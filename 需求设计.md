# 专业选择指导应用需求设计文档

## 项目概述

### 项目简介

本项目是一款智能专业选择指导应用，旨在通过AI语音助手为高中生及其家长提供个性化的专业选择指导服务。应用支持多端访问（Web、iOS、Android、小程序），用户可以通过语音与智能助手进行自然交流，获取专业信息、学科趋势分析、院校推荐等信息。系统具备智能信息爬取、数据可视化、讲解视频生成、邮件推送等功能，帮助学生在人生重要抉择中获得清晰的方向。

### 项目目标

1. **核心目标**：打造一款真正能够帮助高中生解决专业选择困惑的智能应用，让学生在专业选择上不再迷茫，找到适合自己的发展方向
2. **用户体验目标**：建立信任感和亲和力，像朋友一样与学生交流，善于倾听和引导，给予温暖的支持
3. **功能目标**：提供完整的专业选择服务链条，从信息获取、分析推荐到最终决策支持
4. **技术目标**：构建可扩展、高可用的微服务架构，支持多端接入和海量用户并发

### 目标用户

| 用户群体 | 需求特点 |
|---------|---------|
| 高中毕业生 | 缺乏了解、需要引导、决策焦虑 |
| 高中生家长 | 希望了解专业前景、协助孩子决策 |
| 教育工作者 | 需要工具辅助学生指导工作 |

### 核心功能模块

| 模块名称 | 功能描述 | 重要性 |
|---------|---------|--------|
| 语音交互模块 | 支持语音输入和语音输出，实现自然语言对话 | 核心 |
| 智能助手引擎 | 基于大模型的对话系统，具备专业知识和心理引导能力 | 核心 |
| 信息爬取引擎 | 自动爬取网络上的专业信息、院校信息、行业趋势 | 核心 |
| 推荐算法引擎 | 基于用户画像的学科/专业推荐系统 | 核心 |
| 数据可视化模块 | 专业趋势和就业行情的图表展示 | 重要 |
| 视频生成模块 | 生成专业讲解视频 | 重要 |
| 邮件服务模块 | 专业信息推送和报告发送 | 重要 |
| 用户管理模块 | 用户注册、登录、偏好设置、学生档案 | 基础 |
| 多端适配层 | Web、iOS、Android、小程序支持 | 基础 |

---

## 文档规范

### 语言规范

本项目所有文档、代码注释、提交信息均使用**中文**。

| 类型 | 语言要求 | 示例 |
|------|---------|------|
| 项目说明文档 | 中文 | "专业选择指导应用需求设计文档" |
| 模块文档 | 中文 | "爬虫服务 - 专业行情数据爬取" |
| 代码注释 | 中文 | "# 保存数据（自动去重和数量限制）" |
| Git提交信息 | 中文 | "feat(crawler): 新增专业行情自动爬取功能" |
| API接口描述 | 中文 | "获取专业行情数据" |
| 错误信息 | 中文 | "任务不存在" |
| 用户界面文本 | 中文 | "开始对话"、"查看专业" |

### Git提交信息规范

```
<type>(<scope>): <subject>

<body>（可选）

<footer>（可选）
```

**type类型（中文）**：

| type | 说明 | 示例 |
|------|------|------|
| feat | 新功能 | feat(crawler): 新增专业行情爬取功能 |
| fix | 修复bug | fix(user): 修复登录超时问题 |
| docs | 文档更新 | docs: 更新需求设计文档 |
| style | 代码格式 | style: 格式化代码缩进 |
| refactor | 重构 | refactor(chat): 重构对话管理逻辑 |
| perf | 性能优化 | perf: 优化数据库查询 |
| test | 测试 | test: 添加单元测试 |
| chore | 构建/工具 | chore: 更新依赖版本 |

**scope范围（可选）**：

- 前端相关：frontend, web, mobile, miniprogram
- 后端相关：backend, api-gateway, user-service, chat-service, crawler-service
- 数据相关：data, analytics
- 基础设施：devops, docker, ci

**示例**：

```
feat(crawler): 新增自动爬虫定时任务

- 每3天自动执行数据爬取
- 实现数据去重和数量限制
- 新增行情数据查询API

Closes #123
```

---

## 设计思路

### 业务理解与分析

通过对项目描述的深入分析，我们识别出以下核心业务特征：

1. **语音交互为核心交互方式**：用户主要通过语音与应用进行交流，这要求系统具备高质量的语音识别（ASR）、语音合成（TTS）能力，以及流畅的语音对话管理能力。语音助手不是简单的问答机器，而是具备专业选择知识和心理洞察能力的智能伙伴。

2. **专业信息智能处理**：系统需要从海量网络信息中提取有价值的数据，包括专业设置、课程内容、就业方向、薪资水平、发展趋势等。这涉及到网络爬虫、自然语言处理（NLP）、数据清洗和结构化等复杂技术栈。

3. **个性化推荐与引导**：每个学生的情况不同，系统需要建立用户画像，理解学生的学科优势、兴趣爱好、性格特点、家庭背景等多维度信息，然后提供个性化的专业推荐和建议。推荐过程应该是引导式的，逐步帮助学生明确自己的方向。

4. **数据可视化与视频输出**：抽象的专业数据和趋势需要通过直观的图表和视频来呈现，让学生能够轻松理解不同专业的情况和发展前景。视频生成需要结合脚本撰写、配音合成、画面编排等技术。

5. **情感化交互设计**：应用不是冷冰冰的信息展示工具，而是能够理解学生心理、给予关怀和鼓励的智能伙伴。这要求对话系统具备情感计算能力，能够识别学生情绪并做出恰当回应。

6. **高中毕业生专属**：主要服务对象是即将升入大学的高中生，需要考虑他们对未来迷茫、对大学生活憧憬等特殊心理状态。

### 技术选型理由

#### 前端技术栈

| 技术 | 版本 | 用途 | 选择理由 |
|-----|------|------|---------|
| React | 18.x | Web端框架 | 生态成熟、组件化开发、社区活跃 |
| React Native | 0.72.x | 移动端框架 | 跨平台开发、代码复用率高 |
| Vue.js | 3.x | 小程序/轻量端 | 轻量级、学习成本低、适合快速迭代 |
| TypeScript | 5.x | 类型安全 | 减少运行时错误、提升代码可维护性 |
| Socket.IO | 4.x | 实时通信 | 支持双向通信、语音流传输 |
| Chart.js | 4.x | 图表库 | 轻量美观、文档完善 |
| Web Speech API | - | 语音识别/合成 | 浏览器原生支持、降级方案完善 |

#### 后端技术栈

| 技术 | 版本 | 用途 | 选择理由 |
|-----|------|------|---------|
| Python | 3.11 | 主要开发语言 | AI/ML生态丰富、爬虫库完善、开发效率高 |
| FastAPI | 0.109.x | Web框架 | 异步高性能、自动文档生成、类型提示完善 |
| Node.js | 20.x | 实时服务 | 事件驱动、适合高并发WebSocket连接 |
| LangChain | 0.1.x | AI应用框架 | 模块化设计、支持多种LLM、易于扩展 |
| Celery | 5.3.x | 异步任务队列 | 分布式任务调度、任务持久化支持 |
| Redis | 7.x | 缓存/消息队列 | 高性能、支持多种数据结构 |

#### AI与数据处理

| 技术 | 版本 | 用途 | 选择理由 |
|-----|------|------|---------|
| OpenAI GPT-4 | - | 对话模型 | 强大的语言理解和生成能力 |
| Whisper | - | 语音识别 | 多语言支持、准确率高 |
| ElevenLabs | - | 语音合成 | 自然度高、支持情感控制 |
| Scrapy | 2.11 | 爬虫框架 | 异步高效、扩展性强 |
| BeautifulSoup | 4.12 | HTML解析 | 使用简单、兼容性好 |
| Pandas | 2.x | 数据处理 | 功能强大、社区成熟 |
| NumPy | 1.26 | 数值计算 | 基础依赖、性能优异 |

#### 数据库与存储

| 技术 | 版本 | 用途 | 选择理由 |
|-----|------|------|---------|
| PostgreSQL | 15.x | 主数据库 | 功能完整、可靠性高、JSON支持 |
| Redis | 7.x | 缓存层 | 高性能、会话管理 |
| Elasticsearch | 8.x | 搜索引擎 | 全文检索、数据分析 |
| MinIO | - | 对象存储 | S3兼容、私有部署 |
| Chroma | - | 向量数据库 | 知识库检索、相似度匹配 |

#### 基础设施

| 技术 | 版本 | 用途 | 选择理由 |
|-----|------|------|---------|
| Docker | 24.x | 容器化 | 环境一致、部署便捷 |
| Docker Compose | 2.24.x | 容器编排 | 开发环境快速启动 |
| Nginx | 1.25 | 反向代理 | 性能优异、配置灵活 |
| Kafka | 3.6 | 消息队列 | 高吞吐、服务解耦 |
| Prometheus | - | 监控 | 指标采集、告警支持 |

### 架构设计理由

经过对项目需求的深入分析，我们决定采用**微服务架构**，理由如下：

1. **业务复杂度高**：应用包含多个相对独立的业务域（语音交互、信息爬取、推荐系统、可视化、视频生成、邮件服务等），每个业务域都有独特的技术栈和扩展需求，适合拆分为独立服务。

2. **团队协作需求**：项目涉及前端、后端、AI算法、数据工程、运维等多个专业领域，微服务架构可以让各团队独立开发和部署，提高协作效率。

3. **技术多样性**：项目需要用到Python（AI/爬虫）、Node.js（实时通信）、Go（高性能服务）等多种技术栈，微服务架构可以充分发挥各语言的优势。

4. **独立扩展能力**：不同服务的负载特性不同（如语音服务需要GPU资源，爬虫服务需要高并发IO），微服务架构允许对单个服务进行独立扩展。

5. **故障隔离**：某个服务的故障不会影响整体系统可用性，提高系统整体可靠性。

### 功能模块划分

系统按业务域划分为以下微服务：

```
专业选择指导应用
├── api-gateway/                    # API网关服务
│   ├── 路由分发
│   ├── 认证授权
│   ├── 限流熔断
│   └── 请求日志
├── user-service/                   # 用户服务
│   ├── 用户注册/登录
│   ├── 学生档案管理
│   ├── 偏好设置
│   └── 家长账户关联
├── voice-service/                  # 语音服务
│   ├── 语音识别（ASR）
│   ├── 语音合成（TTS）
│   ├── 语音预处理
│   └── 音频流处理
├── chat-service/                   # 对话服务
│   ├── 对话管理
│   ├── 意图识别
│   ├── 情感分析
│   └── 上下文维护
├── crawler-service/                # 爬虫服务
│   ├── 专业信息爬取
│   ├── 院校信息爬取
│   ├── 行业数据爬取
│   └── 反爬处理
├── major-service/                  # 专业服务
│   ├── 专业库管理
│   ├── 学科分类
│   ├── 课程信息
│   └── 专业对比
├── recommendation-service/         # 推荐服务
│   ├── 学生画像引擎
│   ├── 专业推荐引擎
│   ├── 院校匹配引擎
│   └── 推荐解释生成
├── analytics-service/              # 分析服务
│   ├── 专业趋势分析
│   ├── 就业前景分析
│   ├── 图表生成器
│   └── 报告生成器
├── video-service/                  # 视频服务
│   ├── 脚本生成器
│   ├── 配音合成器
│   ├── 画面编排器
│   └── 视频渲染器
├── email-service/                  # 邮件服务
│   ├── 邮件模板管理
│   ├── 邮件发送队列
│   ├── 发送记录管理
│   └── 退订管理
├── knowledge-base/                 # 知识库服务
│   ├── 专业知识图谱
│   ├── 院校知识库
│   ├── 职业发展路径
│   └── FAQ管理
└── notification-service/           # 通知服务
    ├── 消息队列管理
    ├── 多渠道推送
    ├── 消息模板管理
    └── 送达追踪
```

### 数据流设计

系统的核心数据流如下：

```
用户语音输入
    ↓
[voice-service] ASR语音识别 → 文本
    ↓
[api-gateway] 请求路由
    ↓
[chat-service] 意图识别 + 上下文理解
    ↓
    ├──→ [knowledge-base] 专业知识检索（如需）
    ├──→ [recommendation-service] 专业推荐（如需）
    ├──→ [analytics-service] 趋势分析（如需）
    └──→ [crawler-service] 专业信息爬取（如需）
    ↓
[chat-service] 生成回复 + 情感表达
    ↓
[voice-service] TTS语音合成
    ↓
用户语音输出
    ↓
（可选）[email-service] 发送专业报告到邮箱
```

---

## 整体规划

### 开发阶段规划

本项目采用敏捷开发模式，分为五个主要阶段：

#### 第一阶段：基础设施与核心框架（第1-2周）

**主要任务**：

1. 搭建微服务基础架构，完成所有服务的脚手架搭建
2. 部署Kubernetes集群（或Docker Compose开发环境）
3. 配置服务注册与发现、配置中心、日志系统
4. 建立API网关，完成基础路由和认证逻辑
5. 搭建数据库集群，完成数据模型设计
6. 搭建CI/CD流水线，实现自动化测试和部署

**交付物**：

- 微服务基础架构搭建完成
- API网关可正常工作
- 数据库初始化完成
- CI/CD流水线可用

#### 第二阶段：核心功能开发（第3-6周）

**主要任务**：

1. 语音服务开发（ASR、TTS集成）
2. 对话服务核心逻辑开发（意图识别、对话管理）
3. 用户服务开发（注册登录、学生档案）
4. 知识库服务搭建（专业知识图谱）
5. 前端多端框架搭建和基础组件开发

**交付物**：

- 语音对话功能可用
- 用户可以完成注册登录
- 基础对话功能可用
- Web端和移动端Demo可用

#### 第三阶段：业务功能完善（第7-10周）

**主要任务**：

1. 爬虫服务开发（专业信息、院校信息爬取）
2. 推荐算法实现（学生画像、专业匹配）
3. 数据分析模块开发（趋势分析、图表生成）
4. 视频生成服务开发
5. 邮件服务开发
6. 各端应用开发和完善

**交付物**：

- 专业信息爬取功能可用
- 专业推荐功能可用
- 数据分析和可视化功能可用
- 视频生成功能可用
- 邮件发送功能可用

#### 第四阶段：AI能力增强（第11-13周）

**主要任务**：

1. 大模型集成和提示词优化
2. 对话策略优化（心理引导、情感支持）
3. 推荐算法优化（多维度匹配）
4. 知识库扩充和优化
5. 视频生成质量优化

**交付物**：

- 智能助手对话质量显著提升
- 推荐准确率提高
- 视频内容质量优化

#### 第五阶段：测试优化与上线（第14-16周）

**主要任务**：

1. 全链路测试（单元测试、集成测试、压力测试）
2. 性能优化
3. 安全加固
4. 用户验收测试
5. 正式上线

**交付物**：

- 全功能可用的专业选择指导应用
- 完整的测试报告
- 运维文档和监控体系

### Agent分工

根据项目需求，我们设计以下Agent：

| Agent | 职责 | 技术栈 |
|-------|------|-------|
| **Coordinator** | 整体协调、任务拆分、进度管理、结果整合 | - |
| **Frontend** | 前端多端开发（Web、iOS、Android、小程序） | React、React Native、Vue |
| **Backend** | 后端服务开发（API网关、用户服务、对话服务） | Python、FastAPI |
| **AI/ML** | AI能力开发（对话引擎、推荐算法、语音处理） | Python、LangChain |
| **Data** | 数据服务开发（爬虫、分析、可视化） | Python、Scrapy |
| **DevOps** | 基础设施、容器化、CI/CD、监控 | Docker、K8s、Nginx |

### Skill调度

各Agent包含以下核心Skill：

| Agent | Skill | 功能 |
|-------|-------|------|
| Coordinator | coordinator-analyze | 需求分析和任务拆分 |
| Coordinator | coordinator-plan | 整体规划和进度管理 |
| Coordinator | coordinator-integrate | 结果整合和质量把控 |
| Frontend | frontend-analyze | 前端需求分析 |
| Frontend | frontend-plan | 前端技术选型和架构设计 |
| Frontend | frontend-web | Web端开发 |
| Frontend | frontend-mobile | 移动端开发 |
| Frontend | frontend-miniprogram | 小程序开发 |
| Backend | backend-analyze | 后端需求分析 |
| Backend | backend-plan | 后端架构设计 |
| Backend | backend-api | API开发 |
| Backend | backend-gateway | 网关开发 |
| AI/ML | aianalyze | AI需求分析 |
| AI/ML | ai-plan | AI架构设计 |
| AI/ML | ai-chat | 对话引擎开发 |
| AI/ML | ai-voice | 语音处理开发 |
| AI/ML | ai-recommend | 推荐算法开发 |
| Data | data-analyze | 数据需求分析 |
| Data | data-plan | 数据架构设计 |
| Data | data-crawler | 爬虫开发 |
| Data | data-analytics | 数据分析开发 |
| Data | data-visualize | 可视化开发 |
| DevOps | devops-analyze | 运维需求分析 |
| DevOps | devops-plan | 基础设施规划 |
| DevOps | devops-docker | Docker配置 |
| DevOps | devops-k8s | K8s集群配置 |
| DevOps | devops-ci | CI/CD流水线 |

### 里程碑交付物

| 阶段 | 里程碑 | 交付物 |
|-----|--------|-------|
| 第1周 | 基础设施就绪 | 架构文档、代码仓库、CI/CD流水线 |
| 第2周 | 核心框架完成 | API网关、用户服务、数据库初始化 |
| 第4周 | 核心功能可用 | 语音对话、用户注册、Web端Demo |
| 第6周 | 核心功能完善 | 全部基础功能、移动端Demo |
| 第8周 | 业务功能完成 | 爬虫、推荐、分析功能 |
| 第10周 | 高级功能完成 | 视频生成、邮件服务 |
| 第12周 | AI能力增强 | 优化后的对话和推荐 |
| 第14周 | 测试完成 | 测试报告、性能报告 |
| 第16周 | 正式上线 | 生产环境部署、运维文档 |

---

## Docker集成方案

### 容器化策略

本项目采用完全容器化部署策略，所有服务均通过Docker运行：

| 服务类型 | 容器化策略 | 理由 |
|---------|-----------|------|
| 应用服务 | 全部容器化 | 统一部署、便于扩展 |
| 数据库 | 容器化（生产环境可裸机） | 便于管理、数据持久化 |
| 消息队列 | 容器化 | 服务解耦、状态无关 |
| 搜索引擎 | 容器化 | 便于集群管理 |
| 缓存 | 容器化 | 便于扩展 |
| 监控 | 容器化 | 便于部署和维护 |

### 外部服务集成

项目使用以下外部Docker镜像：

| 服务 | 镜像 | 端口 | 说明 |
|-----|------|------|------|
| PostgreSQL | postgres:15-alpine | 5432 | 主数据库 |
| Redis | redis:7-alpine | 6379 | 缓存和会话 |
| Elasticsearch | elasticsearch:8.10 | 9200/9300 | 搜索引擎 |
| MinIO | minio/minio | 9000/9001 | 对象存储 |
| Kafka | confluentinc/cp-kafka:7.4 | 9092 | 消息队列 |
| Zookeeper | confluentinc/cp-zookeeper:7.4 | 2181 | Kafka依赖 |
| Nginx | nginx:alpine | 80/443 | 反向代理 |
| Prometheus | prom/prometheus:v2.47 | 9090 | 监控 |
| Grafana | grafana/grafana:10.2 | 3000 | 可视化面板 |

### 数据持久化方案

```yaml
volumes:
  # 数据库数据
  postgres-data:
    driver: local
  redis-data:
    driver: local
  elasticsearch-data:
    driver: local
  
  # 对象存储
  minio-data:
    driver: local
  
  # 消息队列数据
  kafka-data:
    driver: local
  zookeeper-data:
    driver: local
  
  # 应用数据
  app-uploads:
    driver: local
  app-logs:
    driver: local
  
  # 监控数据
  prometheus-data:
    driver: local
  grafana-data:
    driver: local
```

### 网络配置

```yaml
networks:
  app-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.28.0.0/16
  
  microservices-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.29.0.0/16
    
  monitoring-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.30.0.0/16
```

---

## 项目启动流程

### 启动步骤

#### 步骤一：环境准备

```bash
# 1. 确保已安装Docker和Docker Compose
docker --version    # Docker version 24.0+
docker-compose --version  # Docker Compose version 2.24+

# 2. 克隆代码仓库
git clone <repository-url>
cd major-guidance-app

# 3. 创建环境变量文件
cp .env.example .env
# 编辑.env文件，配置必要的环境变量
```

#### 步骤二：启动基础服务

```bash
# 启动网络和存储层
docker network create app-network || true
docker network create microservices-network || true
docker network create monitoring-network || true

# 启动数据存储服务
docker-compose -f docker-compose.infra.yml up -d

# 验证服务状态
docker-compose -f docker-compose.infra.yml ps
```

#### 步骤三：启动应用服务

```bash
# 启动所有微服务
docker-compose -f docker-compose.yml up -d

# 查看服务状态
docker-compose ps

# 查看启动日志
docker-compose logs -f
```

### 服务启动顺序

```
1. 网络层
   ├── 创建app-network
   ├── 创建microservices-network
   └── 创建monitoring-network

2. 存储层
   ├── PostgreSQL（等待约10秒）
   ├── Redis
   ├── Elasticsearch
   ├── MinIO
   └── 等待所有存储服务健康

3. 消息队列层
   ├── Zookeeper
   └── Kafka

4. 基础设施层
   ├── Nginx
   └── 监控服务（Prometheus、Grafana）

5. 核心服务层
   ├── api-gateway
   ├── user-service
   └── 等待核心服务启动

6. 业务服务层
   ├── voice-service
   ├── chat-service
   ├── crawler-service
   ├── major-service
   ├── recommendation-service
   └── 等待业务服务启动

7. 增强服务层
   ├── analytics-service
   ├── video-service
   ├── email-service
   └── knowledge-base

8. 前端层
   ├── web-frontend
   └── 编译静态资源
```

### 健康检查

```bash
# 检查所有服务健康状态
curl -s http://localhost:80/health | jq

# 单独检查各服务
curl -s http://localhost:8000/health  # api-gateway
curl -s http://localhost:8001/health  # user-service
curl -s http://localhost:8002/health  # voice-service
curl -s http://localhost:8003/health  # chat-service

# 检查数据库连接
docker-compose exec -T postgres pg_isready -U postgres

# 检查Redis连接
docker-compose exec redis redis-cli ping
```

### 故障排查

```bash
# 查看服务日志
docker-compose logs -f [service-name]

# 查看最近的错误日志
docker-compose logs --tail=100 [service-name] | grep -i error

# 进入服务容器排查
docker-compose exec [service-name] /bin/bash

# 检查容器资源使用
docker stats

# 检查网络连通性
docker network inspect app-network
```

---

## Docker Compose命令

### 一键启动

```bash
# 启动所有服务（开发环境）
docker-compose up -d

# 启动所有服务并重新构建镜像
docker-compose up -d --build

# 启动基础服务
docker-compose -f docker-compose.infra.yml up -d

# 启动应用服务
docker-compose -f docker-compose.app.yml up -d
```

### 一键停止

```bash
# 停止所有服务
docker-compose down

# 停止并删除数据卷（谨慎使用，数据将丢失）
docker-compose down -v

# 停止并删除网络
docker-compose down --remove-orphans
```

### 重启服务

```bash
# 重启所有服务
docker-compose restart

# 重启特定服务
docker-compose restart [service-name]

# 重启并重新构建
docker-compose up -d --no-deps [service-name]
```

### 查看状态和日志

```bash
# 查看服务状态
docker-compose ps

# 查看实时日志
docker-compose logs -f

# 查看特定服务日志
docker-compose logs -f [service-name]

# 查看最近的100行日志
docker-compose logs --tail=100
```

### 数据管理

```bash
# 备份数据库
docker-compose exec -T postgres pg_dump -U postgres employment > backup.sql

# 恢复数据库
cat backup.sql | docker-compose exec -T postgres psql -U postgres employment

# 备份Redis数据
docker-compose exec redis redis-cli BGSAVE
docker-compose cp redis:/data/dump.rdb ./redis-backup.rdb

# 清理未使用的数据卷
docker volume prune -f
```

### 扩缩容

```bash
# 扩展服务实例数
docker-compose up -d --scale [service-name]=3

# 查看扩展后的状态
docker-compose ps
```

---

## 环境配置

### 必需环境变量

```bash
# .env 文件模板

# ==================== 通用配置 ====================
NODE_ENV=development
PROJECT_NAME=major-guidance-app
LOG_LEVEL=debug

# ==================== 数据库配置 ====================
POSTGRES_USER=postgres
POSTGRES_PASSWORD=your_secure_password
POSTGRES_DB=employment
DATABASE_URL=postgresql://postgres:your_secure_password@postgres:5432/employment

# ==================== Redis配置 ====================
REDIS_URL=redis://redis:6379
REDIS_PASSWORD=

# ==================== Elasticsearch配置 ====================
ELASTICSEARCH_URL=http://elasticsearch:9200
ELASTICSEARCH_USERNAME=
ELASTICSEARCH_PASSWORD=

# ==================== MinIO配置 ====================
MINIO_ROOT_USER=minioadmin
MINIO_ROOT_PASSWORD=minioadmin
MINIO_ENDPOINT=localhost:9000
MINIO_BUCKET=uploads
MINIO_ACCESS_KEY=your_access_key
MINIO_SECRET_KEY=your_secret_key

# ==================== Kafka配置 ====================
KAFKA_BOOTSTRAP_SERVERS=kafka:29092
KAFKA_USERNAME=
KAFKA_PASSWORD=

# ==================== API密钥 ====================
OPENAI_API_KEY=your_openai_api_key
ELEVENLABS_API_KEY=your_elevenlabs_api_key

# ==================== 邮件服务配置 ====================
SMTP_HOST=smtp.example.com
SMTP_PORT=587
SMTP_USER=your_email@example.com
SMTP_PASSWORD=your_email_password
EMAIL_FROM=noreply@major-app.com

# ==================== 前端配置 ====================
VITE_API_BASE_URL=http://localhost:80/api
VITE_WS_URL=ws://localhost:80/ws

# ==================== 爬虫配置 ====================
CRAWLER_USER_AGENT=Mozilla/5.0 (compatible; MajorApp/1.0)
CRAWLER_DELAY=2
CRAWLER_MAX_CONCURRENT=5
```

### 开发环境配置

```yaml
# docker-compose.dev.yml
version: '3.8'

services:
  # 开发环境特殊配置
  backend:
    volumes:
      - ./backend:/app
      - /app/node_modules
    environment:
      - DEBUG=1
      - HOT_RELOAD=1
    
  frontend:
    volumes:
      - ./frontend:/app
      - /app/node_modules
    environment:
      - VITE_HOT_RELOAD=1
```

### 生产环境配置

```yaml
# docker-compose.prod.yml
version: '3.8'

services:
  # 生产环境配置
  backend:
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '1'
          memory: 1G
    environment:
      - NODE_ENV=production
      - LOG_LEVEL=info
    
  frontend:
    build:
      target: production
```

---

## 架构图

### 系统架构图

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                              客户端层                                        │
├─────────────┬─────────────┬─────────────┬─────────────┬─────────────────────┤
│   Web端      │   iOS端      │  Android端   │   小程序      │  第三方集成          │
│  (React)    │ (React Nat) │ (React Nat) │   (Vue)     │  (API)              │
└──────┬──────┴──────┬──────┴──────┬──────┴──────┬──────┴──────────┬──────────┘
       │             │             │             │                  │
       └─────────────┴──────┬──────┴─────────────┴──────────────────┘
                            │
                            ↓
┌─────────────────────────────────────────────────────────────────────────────┐
│                           API Gateway (Nginx)                                │
│                    路由分发 | 认证授权 | 限流熔断 | 日志                      │
└──────────────────────────────────┬──────────────────────────────────────────┘
                                   │
        ┌──────────────────────────┼──────────────────────────┐
        ↓                          ↓                          ↓
┌───────────────┐      ┌─────────────────────┐      ┌────────────────────────┐
│   用户服务      │      │      语音服务        │      │      对话服务           │
│  user-service  │      │   voice-service     │      │    chat-service        │
│  :8001         │      │     :8002           │      │      :8003             │
└───────┬───────┘      └──────────┬──────────┘      └───────────┬────────────┘
        │                         │                             │
        └─────────────────────────┼─────────────────────────────┘
                                  ↓
┌─────────────────────────────────────────────────────────────────────────────┐
│                           Kafka Message Queue                                │
│              用户事件 | 对话事件 | 推荐事件 | 通知事件 | 分析事件              │
└──────────────────────────────────┬──────────────────────────────────────────┘
                                   │
        ┌──────────────────────────┼──────────────────────────┐
        ↓                          ↓                          ↓
┌───────────────────┐  ┌─────────────────────────┐  ┌─────────────────────────┐
│    爬虫服务         │  │      专业服务            │  │      推荐服务            │
│  crawler-service   │  │    major-service        │  │ recommendation-service  │
│      :8004         │  │       :8005             │  │        :8006            │
└─────────┬─────────┘  └────────────┬────────────┘  └────────────┬────────────┘
          │                         │                             │
          └─────────────────────────┼─────────────────────────────┘
                                    ↓
┌─────────────────────────────────────────────────────────────────────────────┐
│                              数据存储层                                      │
├─────────────┬─────────────┬─────────────┬─────────────┬─────────────────────┤
│  PostgreSQL │    Redis    │ Elasticsearch│    MinIO    │    Chroma DB        │
│  (用户/专业)  │  (缓存/会话) │  (搜索/日志)  │  (文件存储)  │    (向量存储)        │
└─────────────┴─────────────┴─────────────┴─────────────┴─────────────────────┘
```

### 数据流架构图

```
学生语音输入
    │
    ├──→ ASR语音识别 ──→ 文本
    │
    ├──→ 意图识别 ──→ 意图分类
    │
    ├──→ 情感分析 ──→ 情绪判断
    │
    ├──→ 上下文理解 ──→ 状态追踪
    │
    ├──→ 知识检索（专业信息）──→ 相关专业
    │
    ├──→ 推荐引擎（专业推荐）──→ 专业列表
    │
    ├──→ 数据分析（趋势分析）──→ 趋势报告
    │
    ├──→ 爬虫引擎（新信息）──→ 最新数据
    │
    └──→ LLM生成 ──→ 回复文本
              │
              ├──→ 情感表达 ──→ TTS语音合成
              │
              ├──→ 结构化数据 ──→ 图表渲染
              │
              ├──→ 视频脚本 ──→ 视频生成
              │
              └──→ 邮件内容 ──→ 邮件发送
```

---

## 详细功能设计

### 语音交互功能

#### 功能描述

语音交互是本应用的核心交互方式，学生可以通过语音与应用进行自然对话，获得专业选择指导服务。

#### 技术方案

| 功能 | 技术选型 | 说明 |
|-----|---------|------|
| 语音识别 | OpenAI Whisper | 高准确率、多语言支持 |
| 语音合成 | ElevenLabs | 自然度高、支持情感控制 |
| 语音增强 | WebRTC AEC | 回声消除、噪声抑制 |
| 语音缓存 | Redis | 低延迟语音流传输 |

#### 接口设计

```yaml
# 语音对话接口
POST /api/v1/voice/conversation
Request:
  - audio: binary (音频数据)
  - format: string (音频格式: mp3/wav/opus)
  - language: string (语言: zh-CN)
Response:
  - audio_response: binary (语音回复)
  - text_response: string (文本回复)
  - suggestions: array (后续建议)
```

### 智能助手功能

#### 功能描述

智能助手是应用的核心服务，具备专业的学科选择知识，能够理解学生需求，提供个性化建议，并在对话中展现情感共鸣和人文关怀。

#### 技术方案

| 功能 | 技术选型 | 说明 |
|-----|---------|------|
| 对话模型 | GPT-4 + Fine-tuned | 专业化专业指导 |
| 提示工程 | LangChain | 结构化提示模板 |
| 知识检索 | Vector Store (Chroma) | 专业知识向量检索 |
| 上下文管理 | Redis + Session | 多轮对话状态维护 |

#### 心理引导策略

```python
# 对话策略示例
class CounselingStrategy:
    async def handle_choice_anxiety(self, user_message, context):
        # 1. 识别学生情绪
        emotion = await self.analyze_emotion(user_message)
        
        # 2. 根据情绪类型选择回应策略
        strategies = {
            'anxious': self.calming_response,      # 焦虑 → 安抚
            'confused': self.guidance_response,    # 困惑 → 引导
            'frustrated': self.encouragement_response, # 沮丧 → 鼓励
            'confident': self.affirmation_response,   # 自信 → 肯定
            'indecisive': self.exploration_response   # 犹豫 → 探索
        }
        
        # 3. 生成回应
        response = await strategies.get(emotion, self.neutral_response)(user_message, context)
        
        # 4. 添加共情表达
        response = self.add_empathy(response, emotion)
        
        return response
```

### 信息爬取功能

#### 功能描述

系统自动从主流教育网站和高考信息平台爬取专业信息，包括专业设置、课程内容、就业方向、录取分数线等，为学生提供最新的专业信息。

#### 技术方案

| 功能 | 技术选型 | 说明 |
|-----|---------|------|
| 爬虫框架 | Scrapy + Playwright | 异步爬取 + JS渲染 |
| 数据解析 | BeautifulSoup4 + lxml | HTML/XML解析 |
| 数据清洗 | Pandas + NumPy | 数据标准化 |
| 反爬处理 | Rotating Proxies + User-Agent | IP轮换 + 请求伪装 |

#### 爬取目标

| 网站 | 数据类型 | 更新频率 |
|-----|---------|---------|
| 阳光高考 | 专业信息、院校信息 | 每日 |
| 中国教育在线 | 专业介绍、分数线 | 每日 |
| 高考志愿填报 | 专业排名、就业数据 | 每日 |
| 各高校官网 | 招生简章、专业设置 | 每周 |

#### 自动爬取与数据更新机制

##### 功能概述

系统自动定期爬取专业行情数据，确保数据库中始终存储最新的专业信息，为学生提供准确、及时的专业选择参考。

##### 爬取策略

| 参数 | 值 | 说明 |
|-----|------|------|
| 爬取周期 | 每3天 | 系统自动执行 |
| 单次爬取上限 | 500条 | 避免单次任务过重 |
| 数据库最大存储 | 10,000条 | 自动清理旧数据 |
| 数据去重 | 是 | 根据URL+标题去重 |

##### 学科配额规则

系统采用**学科配额制**爬取策略，确保热门学科数据充足，冷门学科也有覆盖：

| 学科类别 | 配额 | 优先级 | 说明 |
|---------|------|--------|------|
| 工学 | 100条 | 10（最高） | 最热门，配额最多 |
| 理学 | 80条 | 9 | 热门专业 |
| 经济学 | 80条 | 9 | 热门专业 |
| 管理学 | 70条 | 8 | 中等热门 |
| 医学 | 60条 | 7 | 重要学科 |
| 法学 | 60条 | 7 | 重要学科 |
| 文学 | 50条 | 6 | 中等学科 |
| 教育学 | 50条 | 6 | 中等学科 |
| 艺术学 | 40条 | 5 | 艺术类 |
| 哲学 | 30条 | 4 | 冷门学科 |
| 历史学 | 30条 | 4 | 冷门学科 |
| 农学 | 30条 | 4 | 冷门学科 |
| 军事学 | 20条 | 3（最低） | 最冷门 |

**配额规则说明**：
1. **总量控制**：所有学科数据总和不超过10,000条
2. **学科上限**：每个学科最多爬取指定配额（如工学最多100条）
3. **优先级**：热门学科优先爬取，低优先级学科在配额用满后跳过
4. **动态调整**：可根据实际需求调整各学科配额

##### 配额管理器

```python
class CrawlerQuotaManager:
    """爬虫配额管理器"""
    
    SUBJECT_QUOTAS = {
        "工学": {"quota": 100, "priority": 10},
        "理学": {"quota": 80, "priority": 9},
        "经济学": {"quota": 80, "priority": 9},
        "管理学": {"quota": 70, "priority": 8},
        "医学": {"quota": 60, "priority": 7},
        "法学": {"quota": 60, "priority": 7},
        "文学": {"quota": 50, "priority": 6},
        "教育学": {"quota": 50, "priority": 6},
        "艺术学": {"quota": 40, "priority": 5},
        "哲学": {"quota": 30, "priority": 4},
        "历史学": {"quota": 30, "priority": 4},
        "农学": {"quota": 30, "priority": 4},
        "军事学": {"quota": 20, "priority": 3},
    }
    
    def can_crawl(self, category: str) -> bool:
        """检查是否可以爬取该学科"""
        pass
    
    def allocate_quota(self, category: str, count: int = 1) -> bool:
        """分配配额"""
        pass
    
    def get_distribution_plan(self, total_items: int) -> Dict[str, int]:
        """获取爬取分配计划（按学科优先级分配）"""
        pass
```

##### 数据保存流程

```
爬取数据
    ↓
检查学科配额（每个学科上限）
    ↓
去重检查（URL+标题）
    ↓
分配配额并保存
    ↓
检查总数是否 > 10000
    ↓ 是 → 删除最旧数据 → 保持10000条
    ↓ 否 → 完成
```

##### API接口

```yaml
# 查看配额状态
GET /api/v1/crawler/quota
Response:
  total_max: 10000       # 最大总量
  total_used: 150        # 已使用
  total_remaining: 9850  # 剩余配额
  subjects:
    工学: {max_quota: 100, current: 50, remaining: 50, priority: 10}
    ...

# 查看配额统计
GET /api/v1/crawler/statistics
Response:
  utilization_rate: 1.5  # 利用率百分比
  subjects:
    工学: {quota: 100, used: 50, rate: 50.0, priority: 10}
    ...
```

##### 自动执行机制

```python
# Celery定时任务配置
from celery import Celery
from celery.schedules import timedelta

app = Celery('crawler')

# 每3天执行一次爬虫任务
app.conf.beat_schedule = {
    'crawl-major-data-every-3-days': {
        'task': 'crawler.crawl_major_data',
        'schedule': timedelta(days=3),
        'options': {'queue': 'crawler'}
    }
}
```

##### 数据库数据管理策略

```python
class MajorDataManager:
    """专业数据管理器 - 保证数据库最多存储10000条最新数据"""
    
    MAX_RECORDS = 10000
    
    def save_crawled_data(self, new_data: List[Dict]):
        """
        保存爬取的数据，并确保数据库不超过最大记录数
        策略：
        1. 去重（根据URL+标题）
        2. 插入新数据
        3. 如果超过10000条，删除最旧的记录
        """
        # 1. 获取现有数据的URL集合（用于去重）
        existing_urls = self.get_existing_urls()
        
        # 2. 过滤掉重复数据
        unique_new_data = [
            item for item in new_data 
            if item['url'] not in existing_urls
        ]
        
        # 3. 批量插入新数据
        if unique_new_data:
            self.batch_insert(unique_new_data)
        
        # 4. 检查并清理旧数据
        self.ensure_max_records()
    
    def ensure_max_records(self):
        """确保数据库中只有最新的10000条数据"""
        current_count = self.get_record_count()
        
        if current_count > self.MAX_RECORDS:
            # 计算需要删除的数量
            excess = current_count - self.MAX_RECORDS
            
            # 删除最旧的excess条记录
            self.delete_oldest_records(excess)
            
            print(f"已清理 {excess} 条旧数据，当前数据库共有 {self.MAX_RECORDS} 条最新记录")
    
    def get_record_count(self) -> int:
        """获取当前数据条数"""
        pass
    
    def get_existing_urls(self) -> set:
        """获取所有现有数据的URL（用于去重）"""
        pass
    
    def batch_insert(self, data: List[Dict]):
        """批量插入数据"""
        pass
    
    def delete_oldest_records(self, count: int):
        """删除最旧的count条记录"""
        pass
```

##### 数据表设计

```sql
-- 专业行情数据表
CREATE TABLE major_market_data (
    id SERIAL PRIMARY KEY,
    title VARCHAR(500) NOT NULL,          -- 数据标题
    major_name VARCHAR(200),               -- 专业名称
    category VARCHAR(100),                 -- 学科门类
    source_url VARCHAR(1000) UNIQUE,       -- 来源URL（用于去重）
    source_website VARCHAR(100),           -- 来源网站
    employment_rate DECIMAL(5,2),          -- 就业率
    avg_salary VARCHAR(100),               -- 平均薪资
    admission_score DECIMAL(5,2),          -- 录取分数线
    heat_index DECIMAL(5,2),               -- 热度指数
    trend_data JSONB,                      -- 趋势数据（JSON）
    description TEXT,                      -- 详细描述
    courses JSONB,                         -- 核心课程
    career_prospects TEXT,                 -- 就业前景
    crawled_at TIMESTAMP DEFAULT NOW(),    -- 爬取时间
    updated_at TIMESTAMP DEFAULT NOW(),    -- 更新时间
    created_at TIMESTAMP DEFAULT NOW()     -- 创建时间
);

-- 创建索引
CREATE INDEX idx_major_market_crawled_at ON major_market_data(crawled_at DESC);
CREATE INDEX idx_major_market_major_name ON major_market_data(major_name);
CREATE INDEX idx_major_market_category ON major_market_data(category);

-- 创建触发器自动更新updated_at
CREATE TRIGGER update_major_market_data_updated_at
    BEFORE UPDATE ON major_market_data
    FOR EACH ROW
    EXECUTE FUNCTION update_updated_at_column();
```

##### 爬取任务状态监控

| 状态 | 说明 |
|-----|------|
| pending | 等待执行 |
| running | 执行中 |
| completed | 成功完成 |
| failed | 执行失败 |
| partially_completed | 部分完成（部分数据失败） |

##### API接口

```yaml
# 获取最新专业行情数据
GET /api/v1/major/market-data
Query Parameters:
  - page: int (default: 1)
  - page_size: int (default: 20, max: 100)
  - category: string (可选，学科门类筛选)
  - sort_by: string (可选，排序字段: crawled_at, heat_index, employment_rate)
  - order: string (可选，排序方向: asc, desc)

Response:
  data:
    - id: int
      major_name: string
      category: string
      employment_rate: float
      avg_salary: string
      heat_index: float
      crawled_at: datetime
  pagination:
    page: int
    page_size: int
    total: int
    total_pages: int

# 触发手动爬取（管理员接口）
POST /api/v1/admin/crawler/trigger
Request:
  - force: boolean (可选，强制立即执行，忽略调度周期)

Response:
  task_id: string
  status: string
  message: string

# 获取爬取任务状态
GET /api/v1/admin/crawler/status/{task_id}
Response:
  task_id: string
  status: string
  started_at: datetime
  completed_at: datetime
  records_crawled: int
  records_saved: int
  error_message: string (如果有)
```

##### 数据保留策略总结

| 数据类型 | 保留策略 |
|---------|---------|
| 专业行情数据 | 最多10000条，保留最新 |
| 临时爬取日志 | 保留7天 |
| 爬取失败记录 | 保留30天 |
| 统计分析数据 | 保留90天 |

---

### 推荐功能

#### 功能描述

基于学生画像和行为数据，为学生推荐适合的专业方向。推荐过程是引导式的，帮助学生逐步明确专业方向。

#### 技术方案

| 功能 | 技术选型 | 说明 |
|-----|---------|------|
| 学生画像 | Spark MLlib | 多维度特征工程 |
| 推荐算法 | 协同过滤 + 内容推荐 | 混合推荐策略 |
| 匹配引擎 | Elasticsearch | 快速相似度计算 |
| 解释生成 | LLM | 推荐理由生成 |

### 数据可视化功能

#### 功能描述

将专业趋势和就业行情数据以直观的图表形式展示，帮助学生了解不同专业的发展前景。

#### 图表类型

| 图表类型 | 数据内容 | 交互功能 |
|---------|---------|---------|
| 折线图 | 专业分数线变化趋势 | 时间范围选择 |
| 柱状图 | 就业率对比 | 维度切换 |
| 饼图 | 学科门类分布 | 悬停详情 |
| 热力图 | 专业热度分布 | 区域筛选 |
| 雷达图 | 专业综合评估 | 动态更新 |

### 视频生成功能

#### 功能描述

基于专业数据和分析报告，自动生成专业讲解视频，帮助学生更直观地了解专业情况。

#### 技术方案

| 功能 | 技术选型 | 说明 |
|-----|---------|------|
| 脚本生成 | GPT-4 | 专业解读文稿 |
| 配音合成 | ElevenLabs | 语音生成 |
| 画面生成 | DALL-E 3 / Stable Diffusion | 配图生成 |
| 视频编排 | FFmpeg | 视频合成 |
| 字幕生成 | Whisper | 字幕同步 |

### 邮件服务功能

#### 功能描述

将学生感兴趣的专业信息、分析报告等发送到学生邮箱，方便学生后续查阅和参考。

#### 邮件类型

| 邮件类型 | 触发条件 | 内容 |
|---------|---------|------|
| 专业推荐 | 学生请求 | 专业列表、推荐理由 |
| 专业报告 | 定期生成 | 专业趋势、数据分析 |
| 重要提醒 | 关键节点 | 高考时间、志愿填报 |
| 系统通知 | 重要事件 | 账户变更、功能更新 |

---

## 用户体验设计

### 对话设计原则

1. **亲和力优先**：对话风格友好温暖，避免机械化的表达方式
2. **主动倾听**：在给出建议前，先确认理解学生的真实需求
3. **适度引导**：不直接告诉答案，而是通过提问引导学生思考
4. **情感共鸣**：理解学生的情绪状态，给予适当的支持和鼓励
5. **案例启发**：适时分享成功案例或故事，提供启发和参考

### 对话示例

```
学生：我不知道该选什么专业，感觉都很迷茫...

助手：我理解你的感受，面对人生重要选择感到迷茫是很正常的。
      （共情表达）
      
      其实，每个人都有自己的兴趣和优势。
      能告诉我，你在高中期间有没有哪门学科是你学起来特别开心，
      或者哪件事情是你做起来特别有成就感的吗？
      （开放性提问，引导学生思考）
```

### 无障碍设计

- 支持语音输入和语音输出
- 字体大小可调节
- 高对比度模式支持
- 语速可调节（TTS）

---

## 安全设计

### 认证授权

| 层级 | 技术 | 说明 |
|-----|------|------|
| 认证 | JWT + Refresh Token | 无状态认证 |
| 授权 | RBAC | 角色权限控制 |
| 传输 | HTTPS + TLS 1.3 | 加密传输 |
| 存储 | AES-256 | 敏感数据加密 |

### 安全措施

- SQL注入防护
- XSS攻击防护
- CSRFToken验证
- 请求频率限制
- API密钥轮换
- 敏感操作审计日志

---

## 性能要求

### 性能指标

| 指标 | 要求 | 说明 |
|-----|------|------|
| API响应时间 | < 500ms | P99 < 1s |
| 语音识别延迟 | < 2s | 端到端 |
| 语音合成延迟 | < 1s | 首字节时间 |
| 页面加载时间 | < 3s | 首屏渲染 |
| 并发用户数 | > 1000 | 同时在线 |
| 可用性 | > 99.9% | 年度可用性 |

### 优化策略

- 多级缓存（CDN → Nginx → Redis → 本地）
- 数据库读写分离
- 消息队列削峰
- 服务横向扩展
- 静态资源CDN加速

---

## 监控告警

### 监控指标

| 维度 | 指标 | 告警阈值 |
|-----|------|---------|
| 系统 | CPU > 80% | 警告 |
| 系统 | 内存 > 85% | 警告 |
| 系统 | 磁盘 > 90% | 严重 |
| 应用 | 错误率 > 1% | 警告 |
| 应用 | 响应时间 > 2s | 警告 |
| 业务 | 语音识别失败率 > 5% | 警告 |
| 业务 | 对话成功率 < 95% | 警告 |

### 监控工具

- **Prometheus**：指标采集和存储
- **Grafana**：可视化面板
- **ELK Stack**：日志收集和分析
- **Alertmanager**：告警管理

---

## 项目文档结构

```
major-guidance-app/
├── .opencode/
│   ├── opencode.json           # 项目配置
│   ├── agent/                   # Agent定义
│   │   ├── coordinator.md
│   │   ├── frontend.md
│   │   ├── backend.md
│   │   ├── ai-ml.md
│   │   ├── data.md
│   │   └── devops.md
│   └── skill/                   # Skill定义
│       ├── coordinator/
│       ├── frontend/
│       ├── backend/
│       ├── ai-ml/
│       ├── data/
│       └── devops/
├── frontend/                    # 前端项目
│   ├── web/                     # Web端
│   │   ├── src/
│   │   ├── public/
│   │   ├── Dockerfile
│   │   └── README.md
│   ├── mobile/                  # 移动端
│   │   ├── src/
│   │   ├── ios/
│   │   ├── android/
│   │   ├── Dockerfile
│   │   └── README.md
│   └── miniprogram/             # 小程序
│       ├── src/
│       └── README.md
├── backend/                     # 后端项目
│   ├── api-gateway/             # API网关
│   ├── user-service/            # 用户服务
│   ├── voice-service/           # 语音服务
│   ├── chat-service/            # 对话服务
│   ├── crawler-service/         # 爬虫服务
│   ├── major-service/           # 专业服务
│   ├── recommendation-service/  # 推荐服务
│   ├── analytics-service/       # 分析服务
│   ├── video-service/           # 视频服务
│   ├── email-service/           # 邮件服务
│   ├── knowledge-base/          # 知识库
│   └── notification-service/    # 通知服务
├── database/
│   ├── migrations/
│   ├── seeds/
│   └── README.md
├── docker/
│   ├── docker-compose.yml
│   ├── docker-compose.dev.yml
│   ├── docker-compose.prod.yml
│   ├── docker-compose.infra.yml
│   ├── .env.example
│   └── nginx/
│       ├── nginx.conf
│       └── README.md
├── docs/
│   ├── ARCHITECTURE.md          # 架构文档
│   ├── API.md                   # API文档
│   ├── DEPLOY.md                # 部署文档
│   └── DEVELOPMENT.md           # 开发文档
├── scripts/
│   ├── setup.sh
│   ├── deploy.sh
│   ├── backup.sh
│   └── manage.sh
├── .gitignore
├── .editorconfig
├── .eslintrc
├── .prettierrc
├── Dockerfile
├── docker-compose.yml
├── Makefile
├── README.md
└── PROJECT_PLAN.md              # 项目规划（本文档）
```

---

## 附录

### 参考资料

- [OpenAI API文档](https://platform.openai.com/docs)
- [Whisper文档](https://github.com/openai/whisper)
- [ElevenLabs API](https://elevenlabs.io/docs/api-docs)
- [FastAPI文档](https://fastapi.tiangolo.com)
- [LangChain文档](https://python.langchain.com)
- [Scrapy文档](https://docs.scrapy.org)
- [Docker官方文档](https://docs.docker.com)
- [Kafka文档](https://kafka.apache.org/documentation)

### 术语表

| 术语 | 定义 |
|-----|------|
| ASR | Automatic Speech Recognition，语音识别 |
| TTS | Text-to-Speech，语音合成 |
| LLM | Large Language Model，大语言模型 |
| RBAC | Role-Based Access Control，基于角色的访问控制 |
| JWT | JSON Web Token，JSON Web令牌 |
| CDN | Content Delivery Network，内容分发网络 |

---

**文档版本**：1.0  
**创建日期**：2026-01-22  
**最后更新**：2026-01-22
