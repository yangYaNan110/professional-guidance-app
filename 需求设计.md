# 专业选择指导应用需求设计文档

## 一、项目概述

### 1.1 项目简介

本项目是一款智能专业选择指导应用，通过AI语音助手为高中生及其家长提供个性化的专业选择指导服务。支持多端访问（Web、iOS、Android、小程序），用户可以通过语音与智能助手进行自然交流，获取专业信息、学科趋势分析、院校推荐等全方位服务。

### 1.2 项目目标

| 目标类型 | 目标描述 |
|---------|---------|
| **核心目标** | 帮助高中生解决专业选择困惑，找到适合自己的发展方向 |
| **体验目标** | 建立信任感和亲和力，像朋友一样与学生交流 |
| **功能目标** | 提供完整的服务链条：信息获取 → 分析推荐 → 决策支持 |
| **技术目标** | 构建可扩展、高可用的微服务架构，支持多端接入和海量并发 |

### 1.3 目标用户

| 用户群体 | 需求特点 |
|---------|---------|
| 高中毕业生 | 缺乏了解、需要引导、决策焦虑 |
| 高中生家长 | 希望了解专业前景、协助孩子决策 |
| 教育工作者 | 需要工具辅助学生指导工作 |

### 1.4 核心功能模块

| 模块 | 功能描述 | 重要性 | 状态 |
|-----|---------|--------|------|
| 语音交互模块 | 支持语音输入和输出，实现自然语言对话 | 核心 | 待开发 |
| 智能助手引擎 | 基于大模型的对话系统，具备专业知识和心理引导能力 | 核心 | 待开发 |
| 信息爬取引擎 | 自动爬取专业信息、院校信息、行业趋势 | 核心 | 已实现 |
| 推荐算法引擎 | 基于用户画像的学科/专业推荐系统 | 核心 | 已实现 |
| 数据可视化模块 | 专业趋势和就业行情的图表展示 | 重要 | 待开发 |
| 视频生成模块 | 生成专业讲解视频 | 重要 | 待开发 |
| 邮件服务模块 | 专业信息推送和报告发送 | 重要 | 待开发 |
| 用户管理模块 | 用户注册、登录、偏好设置、学生档案 | 基础 | 待开发 |
| 多端适配层 | Web、iOS、Android、小程序支持 | 基础 | 开发中 |

---

## 二、文档规范

### 2.1 语言规范

本项目所有文档、代码注释、Git提交信息均使用**中文**。

| 类型 | 语言要求 |
|-----|---------|
| 项目说明文档 | 中文 |
| 模块文档 | 中文 |
| 代码注释 | 中文 |
| Git提交信息 | 中文（feat/fix/docs/style/refactor/perf/test/chore） |
| API接口描述 | 中文 |
| 错误信息 | 中文 |
| 用户界面文本 | 中文 |

### 2.2 大学推荐展示规则

**分组展示原则**：
- **有本省推荐时**：必须展示"📍 同省优质大学"分组标题
- **无本省推荐时**：不展示本省分组，只展示其他分组
- **多分组同时存在**：按优先级顺序展示：分数匹配 → 同省优质 → 全国推荐

**分组优先级**：
1. **🏆 分数匹配大学** (最高优先级)
2. **📍 同省优质大学** (中等优先级)  
3. **🌟 全国推荐大学** (基础优先级)

**展示逻辑**：
- 每个分组都有独立的标题和大学列表
- 分组标题显示该分组的大学数量
- 当某分组为空时，不显示该分组标题
- 至少显示一个分组（全国推荐为兜底）

### 2.5 专业详情页面内容分组规则

#### **分组展示顺序（重要业务需求）**：
- **1️⃣ 专业介绍**：包含专业概念、起源发展、重大事件、现状与未来前景
  - **原则**：用户一进入页面首先看到完整的专业概念介绍，一目了然
  - **内容**：🌱起源与发展、⚡重大事件、🚀现状与爆发、🔮未来展望
  - **要求**：专业概念数据必须整合到专业介绍分组中，不能单独显示

- **2️⃣ 核心课程**：展示专业相关课程列表
  - **内容**：📚核心课程（真实课程数据）
  - **要求**：课程数据必须来自数据库，禁止模拟数据

- **3️⃣ 就业前景**：仅展示就业相关内容
  - **内容**：💼就业方向、发展前景
  - **要求**：只展示就业方向，不包含其他无关内容

- **4️⃣ 注意事项**：提供学习和发展建议
  - **内容**：📚学习要求、💼就业要求、💰薪资与工作强度、🔄职业稳定性、📈发展空间、💡发展建议
  - **要求**：结构化展示六个维度的注意事项

#### **展示顺序固定性规则**：
- **严格顺序**：专业介绍 → 核心课程 → 就业前景 → 注意事项
- **禁止调整**：不得随意更改分组顺序
- **变更权限**：此分组顺序为核心业务需求，后续更改必须用户确认
- **对话记录**：此需求已在对话中记录，新对话窗口必须遵循此顺序

### 2.3 Agent和Skill文件规范

**格式要求**：所有Agent和Skill必须使用Markdown (.md) 格式，禁止使用Python (.py) 格式。

| 类型 | 格式 | 目录 |
|-----|------|------|
| Agent描述 | `.md` | `agents/` |
| Skill描述 | `.md` | `.opencode/skill/` |

### 2.4 Git提交规范

```
<type>(<scope>): <subject>

<body>（可选）
```

**type类型**：

| type | 说明 | 示例 |
|------|------|------|
| feat | 新功能 | feat(crawler): 新增专业行情爬取功能 |
| fix | 修复bug | fix(user): 修复登录超时问题 |
| docs | 文档更新 | docs: 更新需求设计文档 |
| style | 代码格式 | style: 格式化代码缩进 |
| refactor | 重构 | refactor(chat): 重构对话管理逻辑 |
| perf | 性能优化 | perf: 优化数据库查询 |
| test | 测试 | test: 添加单元测试 |
| chore | 构建/工具 | chore: 更新依赖版本 |





---

## 三、数据规范

### 3.1 数据真实性原则

本项目所有页面展示的数据必须来自后端API，**禁止使用假数据或模拟数据**。

| 原则 | 说明 |
|------|------|
| **数据来源** | 所有页面数据必须调用后端API获取 |
| **禁止假数据** | 前端代码中不得包含硬编码的模拟数据 |
| **渐进降级** | API不可用时，显示加载中或空状态 |

### 3.2 数据流规则

```
用户请求
    ↓
前端API调用
    ↓
后端服务（crawler-service等）
    ↓
数据库/爬虫定时写入
    ↓
返回真实数据
```

**核心规则**：
1. 爬虫服务定时采集数据并写入数据库
2. 后端API只从数据库/Redis读取数据
3. 前端通过API获取数据，禁止直接调用爬虫或第三方API

### 3.3 专业列表排序规则

专业推荐列表按照**热度指数（heat_index）**进行排序。

| 排序维度 | 字段 | 优先级 |
|---------|------|--------|
| 热度指数 | heat_index | 默认优先 |
| 就业率 | employment_rate | 可选 |
| 平均薪资 | avg_salary | 可选 |
| 爬取时间 | crawled_at | 兜底 |

**热度指数计算模型**：
```
heat_index = w1 × 搜索热度 + w2 × 就业率 + w3 × 薪资水平 + w4 × 发展趋势 + w5 × 招生规模
```

| 权重 | 含义 | 默认值 |
|-----|------|--------|
| w1 | 搜索热度权重 | 0.30 |
| w2 | 就业率权重 | 0.25 |
| w3 | 薪资水平权重 | 0.20 |
| w4 | 发展趋势权重 | 0.15 |
| w5 | 招生规模权重 | 0.10 |

---

## 四、技术架构

### 4.1 技术选型

#### 前端技术栈

| 技术 | 版本 | 用途 |
|-----|------|------|
| React | 18.x | Web端框架 |
| React Native | 0.72.x | 移动端框架 |
| Vue.js | 3.x | 小程序 |
| TypeScript | 5.x | 类型安全 |
| Socket.IO | 4.x | 实时通信 |

#### 后端技术栈

| 技术 | 版本 | 用途 |
|-----|------|------|
| Python | 3.11 | 主要开发语言 |
| FastAPI | 0.109.x | Web框架 |
| Redis | 7.x | 缓存/消息队列 |
| PostgreSQL | 15.x | 主数据库 |
| Scrapy | 2.11 | 爬虫框架 |

#### AI与数据处理

| 技术 | 用途 |
|-----|------|
| OpenAI GPT-4 | 对话模型 |
| Whisper | 语音识别 |
| ElevenLabs | 语音合成 |
| LangChain | AI应用框架 |
| BeautifulSoup4 | HTML解析 |

### 4.2 微服务架构

```
专业选择指导应用
├── api-gateway/           # API网关服务（路由、认证、限流）
├── user-service/          # 用户服务（注册、登录、档案）
├── voice-service/         # 语音服务（ASR、TTS）
├── chat-service/          # 对话服务（意图识别、情感分析）
├── crawler-service/       # 爬虫服务（数据采集）
├── major-service/         # 专业服务
├── recommendation-service/# 推荐服务
└── ...
```

### 4.3 服务端口规范（严格执行）

**核心原则**：
- **固定端口**：所有服务必须使用固定的端口号，禁止随意更改
- **统一管理**：端口配置集中管理，避免端口冲突
- **文档记录**：所有端口变更必须更新文档并通知团队

#### 端口分配表

| 服务类型 | 服务名称 | 固定端口 | 说明 | 启动顺序 |
|---------|---------|---------|------|---------|
| **数据库服务** | PostgreSQL | 5432 | 主数据库 | 1 |
| **缓存服务** | Redis | 6379 | 缓存/消息队列 | 1 |
| **搜索引擎** | Elasticsearch | 9200/9300 | 搜索引擎 | 1 |
| **消息队列** | Kafka | 9092 | 消息队列 | 1 |
| **API网关** | api-gateway | 8000 | API网关服务 | 3 |
| **用户服务** | user-service | 8001 | 用户管理 | 4 |
| **推荐服务** | recommendation-service | 8002 | 推荐算法 | 4 |
| **专业详情服务** | major-service | 8003 | 专业信息 | 4 |
| **专业市场数据** | market-data-service | 8004 | 专业行情 | 4 |
| **大学推荐** | university-service | 8005 | 大学推荐 | 4 |
| **对话服务** | chat-service | 8006 | 对话引擎 | 4 |
| **语音服务** | voice-service | 8007 | ASR/TTS | 4 |
| **爬虫服务** | crawler-service | 8008 | 数据爬取 | 4 |
| **文档服务** | document-service | 8009 | 文档处理 | 4 |
| **视频服务** | video-service | 8010 | 视频处理 | 4 |
| **分析服务** | analytics-service | 8011 | 数据分析 | 4 |
| **前端服务** | Web前端 | 3000 | React应用 | 5 |
| **移动端** | Mobile | 19000 | React Native | 5 |

#### 端口管理规则

**禁止行为**：
- ❌ **随意更改端口**：未经允许不得修改任何服务的端口号
- ❌ **重复端口分配**：不同服务不得使用相同端口
- ❌ **动态端口分配**：禁止使用随机端口或动态分配

**必须遵守**：
- ✅ **固定配置**：所有服务启动时必须使用固定端口
- ✅ **冲突检查**：启动前检查端口是否被占用
- ✅ **文档同步**：端口变更必须立即更新文档
- ✅ **团队通知**：重大端口变更需要通知所有开发人员

#### 端口配置文件

**全局配置文件**：`backend/config/ports.json`
```json
{
  "version": "1.0.0",
  "last_updated": "2026-01-25",
  "services": {
    "database": {
      "postgresql": 5432,
      "redis": 6379,
      "elasticsearch": 9200
    },
    "infrastructure": {
      "kafka": 9092
    },
    "backend": {
      "api-gateway": 8000,
      "user-service": 8001,
      "recommendation-service": 8002,
      "major-service": 8003,
      "market-data-service": 8004,
      "university-service": 8005,
      "chat-service": 8006,
      "voice-service": 8007,
      "crawler-service": 8008,
      "document-service": 8009,
      "video-service": 8010,
      "analytics-service": 8011
    },
    "frontend": {
      "web": 3000,
      "mobile": 19000
    }
  },
  "rules": {
    "fixed_ports": true,
    "conflict_check": true,
    "auto_restart_on_conflict": false
  }
}
```

#### 启动顺序检查

**启动顺序重要性**：
1. **基础设施层**（端口固定）：数据库、缓存、搜索
2. **服务层**（端口固定）：API网关、业务服务
3. **前端层**（端口固定）：Web应用、移动应用

#### 端口冲突处理

**检测机制**：
- 启动前自动检查端口占用
- 提供详细的冲突报告
- 支持一键清理冲突进程

**处理流程**：
```bash
# 检查端口占用
python scripts/check_ports.py

# 清理冲突进程
python scripts/cleanup_ports.py

# 按顺序启动服务
# 请手动启动各项服务
```

#### 开发环境配置

**前端API配置**：
```typescript
// 前端统一API配置
export const API_CONFIG = {
  BASE_URL: 'http://localhost:8000',  // API网关
  SERVICES: {
    MAJOR_DETAIL: 'http://localhost:8003',     // 专业详情
    MARKET_DATA: 'http://localhost:8004',      // 专业行情
    RECOMMENDATION: 'http://localhost:8002',   // 推荐服务
    UNIVERSITY: 'http://localhost:8005',       // 大学推荐
  }
};
```

**环境变量**：
```bash
# 数据库连接
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
REDIS_HOST=localhost
REDIS_PORT=6379

# API服务
API_GATEWAY_PORT=8000
MAJOR_SERVICE_PORT=8003
MARKET_DATA_SERVICE_PORT=8004
```

#### 生产环境配置

**服务配置**：
```yaml
version: '3.8'
services:
  # 数据库层
  postgres:
    ports:
      - "5432:5432"
  
  redis:
    ports:
      - "6379:6379"
  
  # 服务层
  api-gateway:
    ports:
      - "8000:8000"
  
  major-service:
    ports:
      - "8003:8003"
  
  market-data-service:
    ports:
      - "8004:8004"
```

#### 监控告警

**端口监控**：
- 实时监控所有服务端口状态
- 端口异常时立即告警
- 自动生成端口健康报告

**告警规则**：
- 端口无响应超过30秒
- 端口被意外占用
- 服务端口与配置不符

### 4.3 数据流架构

```
用户语音输入
    ↓
[voice-service] ASR语音识别 → 文本
    ↓
[chat-service] 意图识别 + 上下文理解
    ↓
    ├──→ [knowledge-base] 知识检索
    ├──→ [recommendation-service] 专业推荐
    └──→ [analytics-service] 趋势分析
    ↓
[chat-service] 生成回复 + 情感表达
    ↓
[voice-service] TTS语音合成
    ↓
用户语音输出
```

---

## 五、核心数据表

### 5.1 数据表总览

| 表名 | 业务域 | 数据量级 | 更新频率 | 访问频率 |
|-----|-------|---------|---------|---------|
| major_categories | 基础数据 | ~100条 | 按需 | 中 |
| majors | 基础数据 | ~800条 | 每3天 | 高 |
| major_market_data | 业务数据 | ~10,000条 | 每3天 | 极高 |
| universities | 业务数据 | ~3,000所 | 每年 | 中 |
| university_admission_scores | 业务数据 | ~50,000条 | 每年6-7月 | 高 |
| industry_trends | 动态数据 | ~5,000条 | 每日 | 中 |
| hot_news | 动态数据 | 按需 | 实时 | 中 |
| video_content | 动态数据 | 按需 | 实时 | 中 |

### 5.2 专业行情数据表

```sql
CREATE TABLE major_market_data (
    id SERIAL PRIMARY KEY,
    title VARCHAR(500) NOT NULL,
    major_name VARCHAR(200),
    category VARCHAR(100),
    source_url VARCHAR(1000) UNIQUE,
    source_website VARCHAR(100),
    employment_rate DECIMAL(5,2),
    avg_salary VARCHAR(100),
    admission_score DECIMAL(5,2),
    heat_index DECIMAL(5,2),
    trend_data JSONB,
    description TEXT,
    courses JSONB,
    career_prospects TEXT,
    crawled_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW(),
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_major_market_crawled_at ON major_market_data(crawled_at DESC);
CREATE INDEX idx_major_market_major_name ON major_market_data(major_name);
CREATE INDEX idx_major_market_category ON major_market_data(category);
```

### 5.3 大学录取分数线表

```sql
CREATE TABLE university_admission_scores (
    id SERIAL PRIMARY KEY,
    university_id INT,
    university_name VARCHAR(200),
    major_id INT,
    major_name VARCHAR(200),
    province VARCHAR(100),
    admission_type VARCHAR(50),
    year INT,
    min_score INT,
    max_score INT,
    avg_score DECIMAL(5,2),
    enrollment_count INT,
    FOREIGN KEY (university_id) REFERENCES universities(id)
);

CREATE INDEX idx_admission_province ON university_admission_scores(province);
CREATE INDEX idx_admission_year ON university_admission_scores(year);
```

---

## 六、数据爬取策略

### 6.1 数据源优先级

| 优先级 | 数据源 | 主要数据类型 | 合规风险 |
|-------|--------|-------------|---------|
| P0 | 阳光高考 | 专业信息、录取分数 | 低 |
| P0 | 教育部公开数据 | 学科分类、大学名单 | 低 |
| P1 | 中国教育在线 | 专业介绍、行业资讯 | 低 |
| P1 | 麦可思报告 | 就业率、薪资数据 | 中 |
| P2 | B站 | 视频内容 | 低 |
| P2 | 知乎 | 用户经验分享 | 中 |

### 6.2 动态配置规则

**核心原则**：
爬虫服务必须遵循 `backend/config/crawler_config.json` 配置文件中的所有爬取规则，确保配置的动态性和可维护性。

**配置读取机制**：
- **启动时读取**：服务启动时自动读取配置文件
- **热重载支持**：支持API指令动态重新加载配置
- **配置验证**：配置文件格式错误时使用默认配置并记录日志
- **版本管理**：配置文件包含版本号，支持配置升级

**配置文件路径**：
```
优先级：
1. 环境变量 CRAWLER_CONFIG_PATH
2. backend/config/crawler_config.json (默认)
3. 系统默认配置 (兜底)
```

**配置管理API**：
- `GET /api/v1/admin/config` - 获取当前配置
- `POST /api/v1/admin/config/force-reload` - 强制重新加载配置
- `PUT /api/v1/admin/config/data-source/{type}/cycle` - 动态更新数据源周期

**动态配置内容**：
| 配置项 | 说明 | 支持动态修改 |
|-------|------|-------------|
| 学科配额 | 各学科爬取数量限制 | ✅ |
| 更新周期 | 数据更新频率 | ✅ |
| 数据源 | 爬取数据来源 | ❌ (需重启) |
| 爬虫策略 | quota_based/incremental/daily等 | ❌ (需重启) |
| 缓存TTL | 各数据类型缓存时间 | ✅ |
| 执行窗口 | 爬虫执行时间范围 | ✅ |

**配置更新流程**：
1. 修改 `crawler_config.json` 文件
2. 调用重载API或重启服务
3. 系统验证配置文件格式
4. 应用新的爬取规则
5. 更新调度任务配置
6. 清除相关缓存

**配置变更影响**：
- 新增数据源：下次调度时生效
- 调整配额：立即生效，影响下次爬取
- 修改周期：下次调度检查时生效
- 禁用数据源：立即停止该数据源的爬取任务

### 6.4 全量爬取机制

**触发方式**：
- API指令：`POST /api/v1/admin/crawler/full-crawl`
- 命令行：`python manage.py crawl --full`

**执行流程**：
1. 重置所有学科配额使用计数
2. 标记任务为full模式
3. 遍历所有数据源进行爬取
4. 强制覆盖已有数据（根据source_url）
5. 记录全量爬取日志

### 6.5 动态配置规则

**核心原则**：
爬虫服务必须遵循 `backend/config/crawler_config.json` 配置文件中的所有爬取规则，确保配置的动态性和可维护性。

**配置读取机制**：
- **启动时读取**：服务启动时自动读取配置文件
- **热重载支持**：支持API指令动态重新加载配置
- **配置验证**：配置文件格式错误时使用默认配置并记录日志
- **版本管理**：配置文件包含版本号，支持配置升级

**配置文件路径**：
```
优先级：
1. 环境变量 CRAWLER_CONFIG_PATH
2. backend/config/crawler_config.json (默认)
3. 系统默认配置 (兜底)
```

**配置管理API**：
- `GET /api/v1/admin/config` - 获取当前配置
- `POST /api/v1/admin/config/force-reload` - 强制重新加载配置
- `PUT /api/v1/admin/config/data-source/{type}/cycle` - 动态更新数据源周期

**动态配置内容**：
| 配置项 | 说明 | 支持动态修改 |
|-------|------|-------------|
| 学科配额 | 各学科爬取数量限制 | ✅ |
| 更新周期 | 数据更新频率 | ✅ |
| 数据源 | 爬取数据来源 | ❌ (需重启) |
| 爬虫策略 | quota_based/incremental/daily等 | ❌ (需重启) |
| 缓存TTL | 各数据类型缓存时间 | ✅ |
| 执行窗口 | 爬虫执行时间范围 | ✅ |

**配置更新流程**：
1. 修改 `crawler_config.json` 文件
2. 调用重载API或重启服务
3. 系统验证配置文件格式
4. 应用新的爬取规则
5. 更新调度任务配置
6. 清除相关缓存

**配置变更影响**：
- 新增数据源：下次调度时生效
- 调整配额：立即生效，影响下次爬取
- 修改周期：下次调度检查时生效
- 禁用数据源：立即停止该数据源的爬取任务

### 6.6 开发期间缓存管理规则

**核心原则**：
在开发期间暂时禁用Redis缓存，确保每次API请求都从数据库获取最新数据，避免缓存干扰开发调试。

**缓存禁用规则**：
1. **开发环境**：所有API接口禁用Redis缓存
2. **数据来源**：每次请求直接从PostgreSQL数据库读取
3. **响应头标识**：添加`X-Cache: DISABLED`标识表明缓存已禁用
4. **配置保留**：缓存相关配置代码保留，通过开关控制

**禁用范围**：
- 学科分类API：`GET /api/v1/data/categories`
- 专业列表API：`GET /api/v1/data/majors`
- 大学推荐API：`GET /api/v1/universities/recommend`
- 专业行情API：`GET /api/v1/data/market-data`
- 其他所有数据API接口

**缓存启用流程**：
1. **开发完成确认**：所有功能开发和测试完成
2. **手动启用命令**：收到开发人员明确指令
3. **分步启用**：按照数据类型逐步启用缓存
4. **验证测试**：确保缓存机制正常工作
5. **监控观察**：观察缓存命中率和性能提升

**启用命令**：
```bash
# 启用Redis缓存服务
# 请手动启动Redis服务

# 修改代码启用缓存逻辑（恢复缓存代码注释）
# 重启相关服务验证缓存功能
```

**注意事项**：
- 开发期间禁用缓存仅用于开发环境
- 生产环境必须启用Redis缓存
- 缓存禁用期间API性能会有所下降，属于正常现象
- 所有缓存配置保持完整，便于后续快速启用

---

## 七、缓存策略

### 7.1 缓存层级

| 层级 | 技术 | 用途 |
|-----|------|------|
| L1 | 本地内存 | 用户会话、临时数据 |
| L2 | Redis | 热点数据、API响应（开发期间禁用） |
| L3 | 数据库 | 持久化存储 |

**开发期间禁用说明**：
- 开发期间L2层Redis缓存暂时禁用
- 数据流：L1 → L3（前端 → 数据库）
- 启用时机：等待用户明确指令启用Redis缓存

### 7.2 缓存配置

| 缓存类型 | 缓存键 | TTL | 说明 |
|---------|-------|-----|------|
| 学科分类 | `categories:all` | 24小时 | 变化频率低（开发期间禁用） |
| 专业列表 | `majors:list:{page}:{category}` | 12小时 | 分页数据（开发期间禁用） |
| 专业详情 | `majors:{id}` | 6小时 | 单个专业（开发期间禁用） |
| 大学列表 | `universities:list:{page}:{province}` | 12小时 | 分页数据（开发期间禁用） |
| 行业趋势 | `trends:{industry}` | 12小时 | 趋势数据（开发期间禁用） |
| 热点资讯 | `hot_news:{major}` | 1小时 | 资讯列表（开发期间禁用） |

### 7.3 缓存更新策略

| 策略 | 说明 | 适用场景 |
|-----|------|---------|
| 被动过期 | TTL到期自动失效 | 大多数数据（开发期间禁用） |
| 主动更新 | 爬取完成后主动刷新缓存 | 热门数据（开发期间禁用） |
| 缓存预热 | 定时任务提前加载热点数据 | 重要数据（开发期间禁用） |

**开发期间策略**：
- 所有缓存更新策略暂时禁用
- API直接查询PostgreSQL数据库获取最新数据
- 待用户明确启用缓存后再恢复缓存策略

---

## 八、API接口规范

### 8.1 专业相关接口

#### 获取专业行情数据

```yaml
GET /api/v1/major/market-data
Parameters:
  - page: int (default: 1)
  - page_size: int (default: 20, max: 100)
  - category: string (可选，学科门类筛选)
  - sort_by: string (可选: heat_index, employment_rate, crawled_at, avg_salary)
  - order: string (可选: desc, asc)

Response:
  data:
    - id: int
      major_name: string
      category: string
      employment_rate: float
      avg_salary: string
      heat_index: float
      crawled_at: datetime
  pagination:
    page: int
    page_size: int
    total: int
    total_pages: int
```

#### 获取专业详情

```yaml
GET /api/v1/major/{major_id}/detail
Parameters:
  - province: string (可选，目标省份)
  - score: number (可选，预估分数)

Response:
  id: number
  name: string
  category: string
  heatIndex: number
  employmentRate: number
  avgSalary: string
  courses: string[]
  description: string
  careerProspects: string
  universities:
    - type: string  # score/province/national
      name: string  # 分组名称
      list: []      # 大学列表
```

### 8.2 大学相关接口

#### 获取推荐大学列表

```yaml
GET /api/v1/universities/recommend
Parameters:
  - province: string (可选，目标省份)
  - score: int (可选，预估分数)
  - major: string (专业名称，必填)
  - limit: int (default: 10)

Response:
  universities: [
    {
      id: int
      name: string
      province: string
      city: string
      level: string  # 985/211/双一流等
      employment_rate: float
      match_type: string  # score/province/national
      match_reason: string
      admission_scores: []
      website: string
    }
  ]
  groups:
    score_match:
      name: "🏆 分数匹配大学"
      count: int
      description: "录取分数在您预估分数±30分范围内的高校"
    province_match:
      name: "📍 同省优质大学"
      count: int
      description: "您所在省份内该专业的优质高校"
    national_match:
      name: "🌟 全国推荐大学"
      count: int
      description: "全国范围内该专业的优质高校"
  scenario: string  # A/B/C
  total: int
```



#### 大学推荐场景规则

| 场景 | 条件 | 推荐逻辑 |
|-----|------|---------|
| **A** | 省份+分数+专业 | 同省分数匹配 + 全国分数和专业匹配 |
| **B** | 只有省份+专业 | 同省优质 + 全国优质 |
| **C** | 什么都没填+专业 | 全国优质大学 |

### 8.3 热点资讯接口

```yaml
GET /api/v1/hot-news
Parameters:
  - major: string (专业名称)
  - days: int (default: 180, 时间范围)
  - limit: int (default: 15, 最大数量)

Response:
  success: boolean
  major_name: string
  hot_events:
    - id: int
      title: string
      description: string
      source: string
      publish_time: datetime
      url: string
      heat_index: float
```

### 8.4 爬虫管理接口

```yaml
# 查看配额状态
GET /api/v1/crawler/quota
Response:
  total_max: int
  total_used: int
  total_remaining: int
  subjects: {}

# 触发手动爬取
POST /api/v1/admin/crawler/trigger
Request:
  - force: boolean

# 触发全量爬取
POST /api/v1/admin/crawler/full-crawl
Request:
  - task_type: string (all/major/university/video/trend)

# 获取爬取任务状态
GET /api/v1/admin/crawler/status/{task_id}
```

### 8.5 错误码规范

| 错误码 | 说明 | 处理建议 |
|-------|------|---------|
| 400 | 请求参数错误 | 检查请求参数 |
| 401 | 未授权 | 重新登录 |
| 403 | 禁止访问 | 检查权限 |
| 404 | 资源不存在 | 检查资源ID |
| 429 | 请求过于频繁 | 稍后重试 |
| 500 | 服务器错误 | 联系管理员 |
| 503 | 服务不可用 | 稍后重试 |

---

## 九、大学推荐算法

### 9.1 算法概述

大学推荐基于用户设置的目标（省份、分数、专业）进行智能匹配，采用三场景推荐逻辑。

### 9.2 场景A：省份+分数+专业

```
用户：江苏省 + 620分 + 计算机科学与技术

推荐逻辑：
1. 🏆 同省分数匹配大学：江苏省内录取分在590~650分的大学
   - 筛选条件：省份=江苏，分数=620±30
   - 排序：分数匹配度降序 > 就业率降序
   - 数量：3-5所

2. 🌟 全国分数匹配大学：全国范围内（排除江苏省）录取分在590~650分的大学
   - 筛选条件：省份≠江苏，分数=620±30
   - 排序：分数匹配度降序 > 就业率降序
   - 数量：2-3所
```

#### **场景A分组展示规则（重要更新）**

**核心规则**：当用户同时输入省份、分数、专业时，必须拆分为两个独立分组

**分组优先级**：
1. **🏆 同省分数匹配大学** (省内优先)
2. **🌟 全国分数匹配大学** (全国范围，排除同省)

**分组标题和描述**：
- **同省分数匹配大学**：{省份}省内录取分数{分数-30}-{分数+30}分段的高校
- **全国分数匹配大学**：全国范围内录取分数{分数-30}-{分数+30}分段的高校

**数据筛选逻辑**：
- 同省分组：`province = 目标省份 AND avg_score BETWEEN (分数-30) AND (分数+30)`
- 全国分组：`province != 目标省份 AND avg_score BETWEEN (分数-30) AND (分数+30)`
- 排序规则：按大学层次 + 录取分数降序
- 数量分配：各分组最多返回5所大学

### 9.3 场景B：只有省份+专业

```
用户：江苏省 + 计算机科学与技术

推荐逻辑：
1. 同省优质大学：江苏省内该专业相对排名靠前的大学
   - 筛选条件：省份=江苏，专业匹配度>0
   - 排序：专业匹配度降序 > 大学层次 > 就业率降序
   - 说明：即使该专业在全国排名不高，但在本省相对较好即可推荐
   - 数量：3-5所

2. 全国推荐大学：全国范围内该专业相对排名靠前的大学
   - 筛选条件：全国范围，专业匹配度>0
   - 排序：专业匹配度降序 > 大学层次 > 就业率降序
   - 数量：2-3所
```

### 9.4 场景C：什么都没填+专业

```
用户：计算机科学与技术

推荐逻辑：
1. 全国推荐大学：全国范围内该专业排名靠前的大学
   - 筛选条件：全国范围，专业匹配度>0
   - 排序：专业匹配度降序 > 大学层次 > 就业率降序
   - 数量：5所
```

### 9.5 推荐规则说明

**重要规则变更**：
- **同省优质大学**：考虑本省相对排名，优先推荐高层次大学
- **全国推荐大学**：考虑全国范围内的专业排名
- **专业匹配要求**：在场景B和C中基于`major_strengths`数组判断匹配，在场景A中基于录取分数

**排序优先级**：
1. **大学层次**：985 > 211 > 双一流 > 省属重点 > 其他
2. **专业匹配度**：按匹配程度分层评分
3. **就业率**：就业率高的优先
4. **分数匹配度**：仅用于场景A的分数匹配

**分组展示**：
- 每个分组独立显示，带分组标题和数量统计
- 空分组不显示（如场景A中没有同省推荐时不显示同省分组）
- 至少显示全国推荐分组作为兜底

### 9.6 专业匹配度评分机制

**核心规则：层次优先 + 专业相关度评分**

对于同省优质大学推荐，采用**层次优先原则**：
1. **985大学** > 2. **211大学** > 3. **双一流大学** > 4. **省属重点大学**
2. **同一层次内**，按专业相关度排序
3. **专业不匹配时**，高层次大学仍优先于低层次的匹配大学

**场景B和C的专业匹配逻辑**：

```sql
-- 专业匹配度评分规则
CASE 
    WHEN 目标专业 = ANY(优势专业列表) THEN 1.0                    -- 直接匹配
    WHEN 优势专业列表 IS NULL THEN 0.8                           -- 无专业限制
    WHEN 相关专业匹配 THEN 0.6                                   -- 相关专业
    ELSE 0.3                                                      -- 不相关但兜底推荐
END as major_match_score
```

**排序优先级**：
```sql
ORDER BY 
    level_rank,                    -- 1. 大学层次（985=1, 211=2, 双一流=3, 其他=4）
    major_match_score DESC,        -- 2. 专业匹配度降序
    u.employment_rate DESC        -- 3. 就业率降序
```

**通用专业相关匹配规则**：

根据目标专业动态确定相关专业，覆盖所有主要学科门类：

| 学科门类 | 目标专业示例 | 相关专业（动态匹配） |
|---------|-------------|-------------------|
| **工学** | 人工智能、计算机科学与技术、软件工程、数据科学 | 计算机科学与技术、软件工程、人工智能、自动化、电子信息工程、网络工程、信息安全 |
| **理学** | 数学、物理学、化学、生物学、统计学 | 数学、物理学、化学、生物学、统计学 |
| **经济学** | 经济学、金融学、国际经济与贸易、工商管理、市场营销、会计学 | 经济学、金融学、工商管理、会计学、市场营销、国际经济与贸易 |
| **医学** | 临床医学、口腔医学、中医学、护理学、药学、预防医学 | 临床医学、口腔医学、中医学、护理学、药学、预防医学 |
| **法学** | 法学、政治学与行政学、国际政治、社会学、民族学 | 法学、政治学与行政学、国际政治、社会学、民族学 |
| **文学** | 汉语言文学、历史学、哲学、考古学、文物与博物馆学 | 汉语言文学、历史学、哲学、考古学、文物与博物馆学 |
| **教育学** | 教育学、学前教育、小学教育、特殊教育、教育技术学 | 教育学、学前教育、小学教育、特殊教育、教育技术学 |

**通用专业匹配逻辑总结**：

**动态专业匹配算法**：
```sql
CASE 
    WHEN 目标专业 = ANY(优势专业列表) THEN 1.0                    -- 直接匹配
    WHEN 优势专业列表 IS NULL THEN 0.8                           -- 无专业限制
    WHEN 目标专业属于[工学] AND 存在工学相关专业 THEN 0.6        -- 工科相关专业
    WHEN 目标专业属于[理学] AND 存在理学相关专业 THEN 0.6        -- 理科相关专业  
    WHEN 目标专业属于[经济学] AND 存在经管相关专业 THEN 0.6      -- 经管相关专业
    WHEN 目标专业属于[医学] AND 存在医学相关专业 THEN 0.6        -- 医学相关专业
    WHEN 目标专业属于[法学] AND 存在法学相关专业 THEN 0.6          -- 法学相关专业
    WHEN 目标专业属于[文学] AND 存在文史哲相关专业 THEN 0.6       -- 文史哲相关专业
    WHEN 目标专业属于[教育学] AND 存在教育学相关专业 THEN 0.6     -- 教育学相关专业
    ELSE 0.3                                                          -- 不相关但兜底推荐
END as major_match_score
```

**实际应用场景验证**：

| 目标专业 | 省份 | 推荐逻辑 | 推荐结果 |
|---------|------|---------|---------|
| 人工智能 | 山西 | 优先推荐工科强校 + 211/985层次 | 山西大学(211)、太原理工大学(211)、中北大学(双一流) |
| 社会学 | 山西 | 优先推荐法学类强校 + 211/985层次 | 山西大学(211)、太原理工大学(211)、山西财经大学(省属重点) |
| 经济学 | 山西 | 优先推荐经管类强校 + 211/985层次 | 兜底推荐省内最高层次大学 |
| 临床医学 | 山西 | 优先推荐医学类强校 + 211/985层次 | 兜底推荐省内最高层次大学 |

**兜底机制说明**：
- 当某省份没有目标专业或相关专业时，通过`major_strengths IS NULL`兜底
- 优先推荐该省层次最高的大学（985/211 > 双一流 > 省属重点）
- 确保每个省份都有至少1-3所推荐大学，避免空分组
- 体现"层次优先"原则：即使是低层次的直接匹配，也不如高层次的相关或不相关推荐

**实际应用场景**：
以"人工智能"专业在山西省推荐为例：

| 大学 | 层次 | 优势专业 | 层次排名 | 匹配度评分 | 最终排名 | 排名理由 |
|------|------|----------|----------|------------|----------|----------|
| 山西大学 | 211 | 计算机科学 | 2 | 0.6 | 1 | 211层次 + 相关专业 |
| 太原理工大学 | 211 | 计算机科学 | 2 | 0.6 | 2 | 211层次 + 相关专业 |
| 中北大学 | 双一流 | 计算机科学 | 3 | 0.6 | 3 | 双一流层次 + 相关专业 |
| 山西大同大学 | 省属重点 | 无限制 | 4 | 0.8 | 4 | 省属重点层次（较低） |

**特殊场景处理**：

**场景1：某省内无直接匹配专业**
```
山西省+人工智能：没有大学直接开设人工智能
解决：推荐省内计算机强的211大学，而非开设其他专业的省属重点
```

**场景2：低层次大学有专业匹配**
```
某省属重点大学开设人工智能，但省内无211大学
解决：优先推荐省属重点（专业匹配1.0）
```

**场景3：高层次大学无匹配但有相关专业**
```
某211大学无人工智能，但有计算机科学
解决：优先推荐211大学（层次2 + 相关专业0.6），而非省属重点（层次4）
```

**推荐策略总结**：
1. **层次绝对优先**：211大学即使相关专业也优先于省属重点大学的直接匹配
2. **专业相关度兜底**：无匹配专业时，考虑工科、理科等相关学科
3. **避免层次歧视**：不能因为专业名称差异而排除高层次大学
4. **实用性导向**：考虑学生转专业和交叉学科就业的实际可能性

### 9.6 分数匹配规则

| 参数 | 值 | 说明 |
|-----|------|------|
| 分数范围 | 用户分数 ± 30分 | 例如用户620分，匹配范围590~650分 |
| 排序方式 | 降序 | 分数越高越靠前 |

---

## 十、信息查询规范

### 10.1 数据源优先级

| 优先级 | 数据源 | 说明 |
|-------|--------|------|
| 1 | 阳光高考 | 官方权威数据 |
| 2 | 各高校官网 | 最准确的招生信息 |
| 3 | 中国教育在线 | 专业介绍和排名 |
| 4 | 知乎/B站 | 经验分享和真实体验 |

### 10.2 专业介绍时间线格式

所有专业介绍必须采用**时间线叙述格式**：

```
**起源与发展**
[专业名称]的源头可追溯至[具体时间]的[具体事件/人物]。

**挫折与争议**
[专业]发展历程中经历过[具体挫折/争议]。

**重大突破**
[年份]，[具体事件]是[专业]史上最伟大的[突破/成就]。

**现状与爆发**
当前，[专业]正处于[发展态势]。[具体数据/案例]。

**未来展望**
[专业]未来将在[方向]取得[预期成就]。
```

### 10.3 视频搜索规则

| 筛选标准 | 要求 |
|---------|------|
| 视频数量 | 只返回1个最佳视频 |
| 时长 | 优先3-5分钟的短视频（<300秒最佳） |
| 播放量 | 优先1000+播放的视频 |
| 发布时间 | 优先近2年的视频 |
| 相关度 | 标题和描述必须包含专业名称关键词 |

### 10.4 热点事件规则

**时间范围**：最近180天内的重大事件

**事件类型**：
- 技术突破（如：OpenAI发布GPT-5）
- 行业动态（如：某AI公司上市）
- 政策变化（如：国家发布AI发展规划）
- 重要会议（如：世界AI大会）

**内容过滤**：严格禁止政治敏感内容

---

## 十一、性能要求

### 11.1 性能指标

| 指标 | 要求 | 说明 |
|-----|------|------|
| API响应时间 | < 500ms | P99 < 1s |
| 语音识别延迟 | < 2s | 端到端 |
| 语音合成延迟 | < 1s | 首字节时间 |
| 页面加载时间 | < 3s | 首屏渲染 |
| 并发用户数 | > 1000 | 同时在线 |
| 可用性 | > 99.9% | 年度可用性 |

### 11.2 性能优化策略

| 策略 | 说明 |
|-----|------|
| 多级缓存 | CDN→Redis→应用→数据库 |
| 数据库优化 | 索引设计、读写分离、查询优化 |
| 并发处理 | 异步任务队列、爬虫并发控制 |
| 静态资源 | CDN加速、压缩传输 |

---

## 十二、Agent与Skill

### 12.1 Agent列表

| Agent | 职责 | 技术栈 |
|-------|------|-------|
| Coordinator | 整体协调、任务拆分 | - |
| Frontend | 前端多端开发 | React、RN、Vue |
| Backend | 后端服务开发 | Python、FastAPI |
| AI/ML | AI能力开发 | Python、LangChain |
| Data | 数据服务开发 | Python、Scrapy |
| DevOps | 基础设施、CI/CD | K8s |
| DB-Expert | 数据库设计 | PostgreSQL、Redis |
| DocGenerator | 文档生成 | - |
| DocumentProcessor | 文档处理 | Python、LLM |
| VideoProcessor | 视频处理 | Python、FFmpeg |

### 12.2 Skill列表

| Agent | Skill | 功能 |
|-------|-------|------|
| Data | data-crawler | 爬虫开发 |
| Data | data-analytics | 数据分析开发 |
| Data | data-visualize | 可视化开发 |
| Backend | backend-api | API开发 |
| Backend | backend-gateway | 网关开发 |
| AI/ML | ai-chat | 对话引擎开发 |
| AI/ML | ai-voice | 语音处理开发 |
| AI/ML | ai-recommend | 推荐算法开发 |
| DocumentProcessor | doc-crawler | 文本信息爬取 |
| DocumentProcessor | doc-summarize | 文档智能总结 |
| VideoProcessor | video-search | 视频搜索查找 |
| VideoProcessor | video-summary | 视频摘要生成 |

---

## 十三、部署架构

### 13.2 环境变量

```bash
# 数据库配置
POSTGRES_USER=postgres
POSTGRES_PASSWORD=your_password
POSTGRES_DB=employment
DATABASE_URL=postgresql://postgres:password@postgres:5432/employment

# Redis配置
REDIS_URL=redis://redis:6379

# API密钥
OPENAI_API_KEY=your_openai_api_key
ELEVENLABS_API_KEY=your_elevenlabs_api_key

# 爬虫配置
CRAWLER_USER_AGENT=Mozilla/5.0 (compatible; MajorApp/1.0)
CRAWLER_DELAY=2
CRAWLER_MAX_CONCURRENT=5
```

### 13.3 服务启动顺序

```
1. 存储层 → PostgreSQL, Redis, Elasticsearch
2. 消息队列层 → Zookeeper, Kafka
3. 核心服务层 → api-gateway, user-service
4. 业务服务层 → voice-service, chat-service, crawler-service
5. 前端层 → web-frontend
```

---

## 十四、项目文档结构

```
项目根目录/
├── agents/                          # Agent描述文件
├── .opencode/skill/                 # Skill描述文件
├── frontend/                        # 前端项目
│   ├── web/
│   ├── mobile/
│   └── miniprogram/
├── backend/                         # 后端项目
│   ├── crawler-service/
│   └── ...
├── doc/                             # 文档目录
│   └── crawler_data_analysis.md     # 爬虫数据分析文档

├── scripts/                         # 脚本工具
├── 需求设计.md                       # 本文档
└── README.md
```

---

## 十五、附录

### 15.1 参考资料

- [OpenAI API文档](https://platform.openai.com/docs)
- [Whisper文档](https://github.com/openai/whisper)
- [FastAPI文档](https://fastapi.tiangolo.com)
- [LangChain文档](https://python.langchain.com)
- [Scrapy文档](https://docs.scrapy.org)


### 15.2 术语表

| 术语 | 定义 |
|-----|------|
| ASR | Automatic Speech Recognition，语音识别 |
| TTS | Text-to-Speech，语音合成 |
| LLM | Large Language Model，大语言模型 |
| RBAC | Role-Based Access Control，基于角色的访问控制 |
| JWT | JSON Web Token，JSON Web令牌 |
| CDN | Content Delivery Network，内容分发网络 |

---

**文档版本**：2.2  
**创建日期**：2026-01-22  
**最后更新**：2026-01-25  
**主要变更**： 
- 补充多层次院校推荐设计，增加文档更新权限规则
- 新增服务端口规范（4.3节），确保所有服务使用固定端口
- 修复前端API端口配置不一致问题，统一端口管理
- 创建端口管理脚本和配置文件，提供端口冲突检测和清理功能

---

## 十六、项目管理规范

### **16.1 文档和架构更新权限**

在后续开发中，随着对项目和业务的深入了解，如果需要修改需求设计文档或需要增加更新Agent和Skill，协调调度Agent可以直接处理，但处理前必须与用户确认。

**适用范围**：
- 需求设计文档（本文档）的修改和更新
- Agent描述文件的创建、修改和优化
- Skill技能文件的创建、修改和优化
- 项目架构设计的重要变更

**确认机制**：
1. **变更前确认**：Agent在执行任何修改前必须明确告知用户变更内容、原因和影响
2. **变更记录**：所有变更都必须在文档中记录变更时间、原因和内容
3. **版本管理**：重要变更需要更新文档版本号
4. **变更公示**：重大变更需要及时通知所有相关开发人员

**变更类型**：
- **文档优化**：补充缺失内容、修正错误、统一格式
- **架构调整**：技术选型变更、模块结构调整
- **流程优化**：工作流程改进、协作机制优化
- **新增功能**：根据业务发展需要新增功能模块

**例外情况**：
- **紧急修复**：线上问题的紧急修复可先执行后确认
- **安全更新**：安全相关的紧急更新可先执行后确认
- **性能优化**：不影响功能的性能优化可先执行后确认

这种机制确保项目能够随着业务发展灵活调整，同时保持项目的稳定性和可控性。
