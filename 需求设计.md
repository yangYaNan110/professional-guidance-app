# 专业选择指导应用需求设计文档

## 一、项目概述

### 1.1 项目简介

本项目是一款智能专业选择指导应用，通过AI语音助手为高中生及其家长提供个性化的专业选择指导服务。支持多端访问（Web、iOS、Android、小程序），用户可以通过语音与智能助手进行自然交流，获取专业信息、学科趋势分析、院校推荐等全方位服务。

### 1.2 项目目标

| 目标类型 | 目标描述 |
|---------|---------|
| **核心目标** | 帮助高中生解决专业选择困惑，找到适合自己的发展方向 |
| **体验目标** | 建立信任感和亲和力，像朋友一样与学生交流 |
| **功能目标** | 提供完整的服务链条：信息获取 → 分析推荐 → 决策支持 |
| **技术目标** | 构建可扩展、高可用的微服务架构，支持多端接入和海量并发 |

### 1.3 目标用户

| 用户群体 | 需求特点 |
|---------|---------|
| 高中毕业生 | 缺乏了解、需要引导、决策焦虑 |
| 高中生家长 | 希望了解专业前景、协助孩子决策 |
| 教育工作者 | 需要工具辅助学生指导工作 |

### 1.4 核心功能模块

| 模块 | 功能描述 | 重要性 | 状态 |
|-----|---------|--------|------|
| 语音交互模块 | 支持语音输入和输出，实现自然语言对话 | 核心 | 待开发 |
| 智能助手引擎 | 基于大模型的对话系统，具备专业知识和心理引导能力 | 核心 | 待开发 |
| 信息爬取引擎 | 自动爬取专业信息、院校信息、行业趋势 | 核心 | 已实现 |
| 推荐算法引擎 | 基于用户画像的学科/专业推荐系统 | 核心 | 已实现 |
| 数据可视化模块 | 专业趋势和就业行情的图表展示 | 重要 | 待开发 |
| 视频生成模块 | 生成专业讲解视频 | 重要 | 待开发 |
| 邮件服务模块 | 专业信息推送和报告发送 | 重要 | 待开发 |
| 用户管理模块 | 用户注册、登录、偏好设置、学生档案 | 基础 | 待开发 |
| 多端适配层 | Web、iOS、Android、小程序支持 | 基础 | 开发中 |

---

## 二、文档规范

### 2.1 语言规范

本项目所有文档、代码注释、Git提交信息均使用**中文**。

| 类型 | 语言要求 |
|-----|---------|
| 项目说明文档 | 中文 |
| 模块文档 | 中文 |
| 代码注释 | 中文 |
| Git提交信息 | 中文（feat/fix/docs/style/refactor/perf/test/chore） |
| API接口描述 | 中文 |
| 错误信息 | 中文 |
| 用户界面文本 | 中文 |

### 2.2 Agent和Skill文件规范

**格式要求**：所有Agent和Skill必须使用Markdown (.md) 格式，禁止使用Python (.py) 格式。

| 类型 | 格式 | 目录 |
|-----|------|------|
| Agent描述 | `.md` | `agents/` |
| Skill描述 | `.md` | `.opencode/skill/` |

### 2.3 Git提交规范

```
<type>(<scope>): <subject>

<body>（可选）
```

**type类型**：

| type | 说明 | 示例 |
|------|------|------|
| feat | 新功能 | feat(crawler): 新增专业行情爬取功能 |
| fix | 修复bug | fix(user): 修复登录超时问题 |
| docs | 文档更新 | docs: 更新需求设计文档 |
| style | 代码格式 | style: 格式化代码缩进 |
| refactor | 重构 | refactor(chat): 重构对话管理逻辑 |
| perf | 性能优化 | perf: 优化数据库查询 |
| test | 测试 | test: 添加单元测试 |
| chore | 构建/工具 | chore: 更新依赖版本 |

---

## 三、数据规范

### 3.1 数据真实性原则

本项目所有页面展示的数据必须来自后端API，**禁止使用假数据或模拟数据**。

| 原则 | 说明 |
|------|------|
| **数据来源** | 所有页面数据必须调用后端API获取 |
| **禁止假数据** | 前端代码中不得包含硬编码的模拟数据 |
| **渐进降级** | API不可用时，显示加载中或空状态 |

### 3.2 数据流规则

```
用户请求
    ↓
前端API调用
    ↓
后端服务（crawler-service等）
    ↓
数据库/爬虫定时写入
    ↓
返回真实数据
```

**核心规则**：
1. 爬虫服务定时采集数据并写入数据库
2. 后端API只从数据库/Redis读取数据
3. 前端通过API获取数据，禁止直接调用爬虫或第三方API

### 3.3 专业列表排序规则

专业推荐列表按照**热度指数（heat_index）**进行排序。

| 排序维度 | 字段 | 优先级 |
|---------|------|--------|
| 热度指数 | heat_index | 默认优先 |
| 就业率 | employment_rate | 可选 |
| 平均薪资 | avg_salary | 可选 |
| 爬取时间 | crawled_at | 兜底 |

**热度指数计算模型**：
```
heat_index = w1 × 搜索热度 + w2 × 就业率 + w3 × 薪资水平 + w4 × 发展趋势 + w5 × 招生规模
```

| 权重 | 含义 | 默认值 |
|-----|------|--------|
| w1 | 搜索热度权重 | 0.30 |
| w2 | 就业率权重 | 0.25 |
| w3 | 薪资水平权重 | 0.20 |
| w4 | 发展趋势权重 | 0.15 |
| w5 | 招生规模权重 | 0.10 |

---

## 四、技术架构

### 4.1 技术选型

#### 前端技术栈

| 技术 | 版本 | 用途 |
|-----|------|------|
| React | 18.x | Web端框架 |
| React Native | 0.72.x | 移动端框架 |
| Vue.js | 3.x | 小程序 |
| TypeScript | 5.x | 类型安全 |
| Socket.IO | 4.x | 实时通信 |

#### 后端技术栈

| 技术 | 版本 | 用途 |
|-----|------|------|
| Python | 3.11 | 主要开发语言 |
| FastAPI | 0.109.x | Web框架 |
| Redis | 7.x | 缓存/消息队列 |
| PostgreSQL | 15.x | 主数据库 |
| Scrapy | 2.11 | 爬虫框架 |

#### AI与数据处理

| 技术 | 用途 |
|-----|------|
| OpenAI GPT-4 | 对话模型 |
| Whisper | 语音识别 |
| ElevenLabs | 语音合成 |
| LangChain | AI应用框架 |
| BeautifulSoup4 | HTML解析 |

### 4.2 微服务架构

```
专业选择指导应用
├── api-gateway/           # API网关服务（路由、认证、限流）
├── user-service/          # 用户服务（注册、登录、档案）
├── voice-service/         # 语音服务（ASR、TTS）
├── chat-service/          # 对话服务（意图识别、情感分析）
├── crawler-service/       # 爬虫服务（数据采集）
├── major-service/         # 专业服务
├── recommendation-service/# 推荐服务
└── ...
```

### 4.3 数据流架构

```
用户语音输入
    ↓
[voice-service] ASR语音识别 → 文本
    ↓
[chat-service] 意图识别 + 上下文理解
    ↓
    ├──→ [knowledge-base] 知识检索
    ├──→ [recommendation-service] 专业推荐
    └──→ [analytics-service] 趋势分析
    ↓
[chat-service] 生成回复 + 情感表达
    ↓
[voice-service] TTS语音合成
    ↓
用户语音输出
```

---

## 五、核心数据表

### 5.1 数据表总览

| 表名 | 业务域 | 数据量级 | 更新频率 | 访问频率 |
|-----|-------|---------|---------|---------|
| major_categories | 基础数据 | ~100条 | 按需 | 中 |
| majors | 基础数据 | ~800条 | 每3天 | 高 |
| major_market_data | 业务数据 | ~10,000条 | 每3天 | 极高 |
| universities | 业务数据 | ~3,000所 | 每年 | 中 |
| university_admission_scores | 业务数据 | ~50,000条 | 每年6-7月 | 高 |
| industry_trends | 动态数据 | ~5,000条 | 每日 | 中 |
| hot_news | 动态数据 | 按需 | 实时 | 中 |
| video_content | 动态数据 | 按需 | 实时 | 中 |

### 5.2 专业行情数据表

```sql
CREATE TABLE major_market_data (
    id SERIAL PRIMARY KEY,
    title VARCHAR(500) NOT NULL,
    major_name VARCHAR(200),
    category VARCHAR(100),
    source_url VARCHAR(1000) UNIQUE,
    source_website VARCHAR(100),
    employment_rate DECIMAL(5,2),
    avg_salary VARCHAR(100),
    admission_score DECIMAL(5,2),
    heat_index DECIMAL(5,2),
    trend_data JSONB,
    description TEXT,
    courses JSONB,
    career_prospects TEXT,
    crawled_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW(),
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_major_market_crawled_at ON major_market_data(crawled_at DESC);
CREATE INDEX idx_major_market_major_name ON major_market_data(major_name);
CREATE INDEX idx_major_market_category ON major_market_data(category);
```

### 5.3 大学录取分数线表

```sql
CREATE TABLE university_admission_scores (
    id SERIAL PRIMARY KEY,
    university_id INT,
    university_name VARCHAR(200),
    major_id INT,
    major_name VARCHAR(200),
    province VARCHAR(100),
    admission_type VARCHAR(50),
    year INT,
    min_score INT,
    max_score INT,
    avg_score DECIMAL(5,2),
    enrollment_count INT,
    FOREIGN KEY (university_id) REFERENCES universities(id)
);

CREATE INDEX idx_admission_province ON university_admission_scores(province);
CREATE INDEX idx_admission_year ON university_admission_scores(year);
```

---

## 六、数据爬取策略

### 6.1 数据源优先级

| 优先级 | 数据源 | 主要数据类型 | 合规风险 |
|-------|--------|-------------|---------|
| P0 | 阳光高考 | 专业信息、录取分数 | 低 |
| P0 | 教育部公开数据 | 学科分类、大学名单 | 低 |
| P1 | 中国教育在线 | 专业介绍、行业资讯 | 低 |
| P1 | 麦可思报告 | 就业率、薪资数据 | 中 |
| P2 | B站 | 视频内容 | 低 |
| P2 | 知乎 | 用户经验分享 | 中 |

### 6.2 学科配额规则

| 学科类别 | 配额 | 优先级 | 说明 |
|---------|------|--------|------|
| 工学 | 100条 | 10 | 最热门 |
| 理学 | 80条 | 9 | 热门 |
| 经济学 | 80条 | 9 | 热门 |
| 管理学 | 70条 | 8 | 中等 |
| 医学 | 60条 | 7 | 重要 |
| 法学 | 60条 | 7 | 重要 |
| 文学 | 50条 | 6 | 中等 |
| 教育学 | 50条 | 6 | 中等 |
| 艺术学 | 40条 | 5 | 艺术类 |
| 哲学/历史/农学 | 30条 | 4 | 冷门 |
| 军事学 | 20条 | 3 | 最冷门 |

**配额规则**：
1. 所有学科数据总和不超过10,000条
2. 每个学科最多爬取指定配额
3. 热门学科优先爬取

### 6.3 更新周期

| 数据类型 | 更新周期 | 触发时间 | 爬虫Agent |
|---------|---------|---------|----------|
| 热门专业行情 | 每3天 | 凌晨2:00 | data-crawler |
| 大学录取分数 | 每年 | 6月25日 | data-crawler |
| 行业趋势 | 每日 | 上午6:00 | data-crawler |
| 热点资讯 | 实时 | 用户查询时 | data-crawler |
| 视频内容 | 实时 | 用户查询时 | video-processor |

### 6.4 全量爬取机制

**触发方式**：
- API指令：`POST /api/v1/admin/crawler/full-crawl`
- 命令行：`python manage.py crawl --full`

**执行流程**：
1. 重置所有学科配额使用计数
2. 标记任务为full模式
3. 遍历所有数据源进行爬取
4. 强制覆盖已有数据（根据source_url）
5. 记录全量爬取日志

---

## 七、缓存策略

### 7.1 缓存层级

| 层级 | 技术 | 用途 |
|-----|------|------|
| L1 | 本地内存 | 用户会话、临时数据 |
| L2 | Redis | 热点数据、API响应 |
| L3 | 数据库 | 持久化存储 |

### 7.2 缓存配置

| 缓存类型 | 缓存键 | TTL | 说明 |
|---------|-------|-----|------|
| 学科分类 | `categories:all` | 24小时 | 变化频率低 |
| 专业列表 | `majors:list:{page}:{category}` | 12小时 | 分页数据 |
| 专业详情 | `majors:{id}` | 6小时 | 单个专业 |
| 大学列表 | `universities:list:{page}:{province}` | 12小时 | 分页数据 |
| 行业趋势 | `trends:{industry}` | 12小时 | 趋势数据 |
| 热点资讯 | `hot_news:{major}` | 1小时 | 资讯列表 |

### 7.3 缓存更新策略

| 策略 | 说明 | 适用场景 |
|-----|------|---------|
| 被动过期 | TTL到期自动失效 | 大多数数据 |
| 主动更新 | 爬取完成后主动刷新缓存 | 热门数据 |
| 缓存预热 | 定时任务提前加载热点数据 | 重要数据 |

---

## 八、API接口规范

### 8.1 专业相关接口

#### 获取专业行情数据

```yaml
GET /api/v1/major/market-data
Parameters:
  - page: int (default: 1)
  - page_size: int (default: 20, max: 100)
  - category: string (可选，学科门类筛选)
  - sort_by: string (可选: heat_index, employment_rate, crawled_at, avg_salary)
  - order: string (可选: desc, asc)

Response:
  data:
    - id: int
      major_name: string
      category: string
      employment_rate: float
      avg_salary: string
      heat_index: float
      crawled_at: datetime
  pagination:
    page: int
    page_size: int
    total: int
    total_pages: int
```

#### 获取专业详情

```yaml
GET /api/v1/major/{major_id}/detail
Parameters:
  - province: string (可选，目标省份)
  - score: number (可选，预估分数)

Response:
  id: number
  name: string
  category: string
  heatIndex: number
  employmentRate: number
  avgSalary: string
  courses: string[]
  description: string
  careerProspects: string
  universities:
    - type: string  # score/province/national
      name: string  # 分组名称
      list: []      # 大学列表
```

### 8.2 大学相关接口

#### 获取推荐大学列表

```yaml
GET /api/v1/universities/recommend
Parameters:
  - province: string (可选，目标省份)
  - score: int (可选，预估分数)
  - major: string (专业名称，必填)
  - limit: int (default: 10)

Response:
  universities: []
  groups:
    score_match:
      name: "🏆 分数匹配大学"
      count: int
      description: "录取分数在您预估分数±30分范围内的高校"
    province_match:
      name: "📍 同省优质大学"
      count: int
      description: "您所在省份内该专业的优质高校"
    national_match:
      name: "🌟 全国推荐大学"
      count: int
      description: "全国范围内该专业的优质高校"
  scenario: string  # A/B/C
  total: int
```

#### 大学推荐场景规则

| 场景 | 条件 | 推荐逻辑 |
|-----|------|---------|
| **A** | 省份+分数+专业 | 同省分数匹配 + 全国分数和专业匹配 |
| **B** | 只有省份+专业 | 同省优质 + 全国优质 |
| **C** | 什么都没填+专业 | 全国优质大学 |

### 8.3 热点资讯接口

```yaml
GET /api/v1/hot-news
Parameters:
  - major: string (专业名称)
  - days: int (default: 180, 时间范围)
  - limit: int (default: 15, 最大数量)

Response:
  success: boolean
  major_name: string
  hot_events:
    - id: int
      title: string
      description: string
      source: string
      publish_time: datetime
      url: string
      heat_index: float
```

### 8.4 爬虫管理接口

```yaml
# 查看配额状态
GET /api/v1/crawler/quota
Response:
  total_max: int
  total_used: int
  total_remaining: int
  subjects: {}

# 触发手动爬取
POST /api/v1/admin/crawler/trigger
Request:
  - force: boolean

# 触发全量爬取
POST /api/v1/admin/crawler/full-crawl
Request:
  - task_type: string (all/major/university/video/trend)

# 获取爬取任务状态
GET /api/v1/admin/crawler/status/{task_id}
```

### 8.5 错误码规范

| 错误码 | 说明 | 处理建议 |
|-------|------|---------|
| 400 | 请求参数错误 | 检查请求参数 |
| 401 | 未授权 | 重新登录 |
| 403 | 禁止访问 | 检查权限 |
| 404 | 资源不存在 | 检查资源ID |
| 429 | 请求过于频繁 | 稍后重试 |
| 500 | 服务器错误 | 联系管理员 |
| 503 | 服务不可用 | 稍后重试 |

---

## 九、大学推荐算法

### 9.1 算法概述

大学推荐基于用户设置的目标（省份、分数、专业）进行智能匹配，采用三场景推荐逻辑。

### 9.2 场景A：省份+分数+专业

```
用户：江苏省 + 620分 + 计算机科学与技术

推荐逻辑：
1. 同省分数匹配大学：江苏省内录取分在590~650分的计算机相关专业
   - 筛选条件：省份=江苏，分数=620±30
   - 排序：分数匹配度降序 > 就业率降序
   - 数量：3-5所

2. 全国分数和专业匹配大学：全国范围内符合分数和专业的大学
   - 筛选条件：分数=620±30，专业匹配度>0
   - 排序：分数匹配度降序 > 就业率降序
   - 数量：2-3所
```

### 9.3 场景B：只有省份+专业

```
用户：江苏省 + 计算机科学与技术

推荐逻辑：
1. 同省优质大学：江苏省内计算机科学与技术专业匹配度>0的大学
   - 排序：专业匹配度降序 > 就业率降序
   - 数量：3-5所

2. 全国优质大学：全国范围内计算机科学与技术专业匹配度高的大学
   - 排序：专业匹配度降序 > 就业率降序
   - 数量：2-3所
```

### 9.4 场景C：什么都没填+专业

```
用户：计算机科学与技术

推荐逻辑：
1. 全国优质大学：计算机科学与技术专业匹配度最高的大学
   - 排序：专业匹配度降序 > 就业率降序 > 知名度
   - 数量：5所
```

### 9.5 专业匹配度计算

```
专业匹配度 = 基于大学王牌专业与目标专业的重合度

匹配度评分：
- 重合专业数 >= 2：100分
- 重合专业数 = 1：60分
- 同属一个学科门类：30分
- 无匹配：0分
```

### 9.6 分数匹配规则

| 参数 | 值 | 说明 |
|-----|------|------|
| 分数范围 | 用户分数 ± 30分 | 例如用户620分，匹配范围590~650分 |
| 排序方式 | 降序 | 分数越高越靠前 |

---

## 十、信息查询规范

### 10.1 数据源优先级

| 优先级 | 数据源 | 说明 |
|-------|--------|------|
| 1 | 阳光高考 | 官方权威数据 |
| 2 | 各高校官网 | 最准确的招生信息 |
| 3 | 中国教育在线 | 专业介绍和排名 |
| 4 | 知乎/B站 | 经验分享和真实体验 |

### 10.2 专业介绍时间线格式

所有专业介绍必须采用**时间线叙述格式**：

```
**起源与发展**
[专业名称]的源头可追溯至[具体时间]的[具体事件/人物]。

**挫折与争议**
[专业]发展历程中经历过[具体挫折/争议]。

**重大突破**
[年份]，[具体事件]是[专业]史上最伟大的[突破/成就]。

**现状与爆发**
当前，[专业]正处于[发展态势]。[具体数据/案例]。

**未来展望**
[专业]未来将在[方向]取得[预期成就]。
```

### 10.3 视频搜索规则

| 筛选标准 | 要求 |
|---------|------|
| 视频数量 | 只返回1个最佳视频 |
| 时长 | 优先3-5分钟的短视频（<300秒最佳） |
| 播放量 | 优先1000+播放的视频 |
| 发布时间 | 优先近2年的视频 |
| 相关度 | 标题和描述必须包含专业名称关键词 |

### 10.4 热点事件规则

**时间范围**：最近180天内的重大事件

**事件类型**：
- 技术突破（如：OpenAI发布GPT-5）
- 行业动态（如：某AI公司上市）
- 政策变化（如：国家发布AI发展规划）
- 重要会议（如：世界AI大会）

**内容过滤**：严格禁止政治敏感内容

---

## 十一、性能要求

### 11.1 性能指标

| 指标 | 要求 | 说明 |
|-----|------|------|
| API响应时间 | < 500ms | P99 < 1s |
| 语音识别延迟 | < 2s | 端到端 |
| 语音合成延迟 | < 1s | 首字节时间 |
| 页面加载时间 | < 3s | 首屏渲染 |
| 并发用户数 | > 1000 | 同时在线 |
| 可用性 | > 99.9% | 年度可用性 |

### 11.2 性能优化策略

| 策略 | 说明 |
|-----|------|
| 多级缓存 | CDN→Nginx→Redis→应用→数据库 |
| 数据库优化 | 索引设计、读写分离、查询优化 |
| 并发处理 | 异步任务队列、爬虫并发控制 |
| 静态资源 | CDN加速、压缩传输 |

---

## 十二、Agent与Skill

### 12.1 Agent列表

| Agent | 职责 | 技术栈 |
|-------|------|-------|
| Coordinator | 整体协调、任务拆分 | - |
| Frontend | 前端多端开发 | React、RN、Vue |
| Backend | 后端服务开发 | Python、FastAPI |
| AI/ML | AI能力开发 | Python、LangChain |
| Data | 数据服务开发 | Python、Scrapy |
| DevOps | 基础设施、CI/CD | Docker、K8s |
| DB-Expert | 数据库设计 | PostgreSQL、Redis |
| DocGenerator | 文档生成 | - |
| DocumentProcessor | 文档处理 | Python、LLM |
| VideoProcessor | 视频处理 | Python、FFmpeg |

### 12.2 Skill列表

| Agent | Skill | 功能 |
|-------|-------|------|
| Data | data-crawler | 爬虫开发 |
| Data | data-analytics | 数据分析开发 |
| Data | data-visualize | 可视化开发 |
| Backend | backend-api | API开发 |
| Backend | backend-gateway | 网关开发 |
| AI/ML | ai-chat | 对话引擎开发 |
| AI/ML | ai-voice | 语音处理开发 |
| AI/ML | ai-recommend | 推荐算法开发 |
| DocumentProcessor | doc-crawler | 文本信息爬取 |
| DocumentProcessor | doc-summarize | 文档智能总结 |
| VideoProcessor | video-search | 视频搜索查找 |
| VideoProcessor | video-summary | 视频摘要生成 |

---

## 十三、容器化与部署

### 13.1 Docker服务

| 服务 | 镜像 | 端口 | 说明 |
|-----|------|------|------|
| PostgreSQL | postgres:15-alpine | 5432 | 主数据库 |
| Redis | redis:7-alpine | 6379 | 缓存/会话 |
| Elasticsearch | elasticsearch:8.10 | 9200/9300 | 搜索引擎 |
| MinIO | minio/minio | 9000/9001 | 对象存储 |
| Kafka | confluentinc/cp-kafka:7.4 | 9092 | 消息队列 |
| Nginx | nginx:alpine | 80/443 | 反向代理 |

### 13.2 环境变量

```bash
# 数据库配置
POSTGRES_USER=postgres
POSTGRES_PASSWORD=your_password
POSTGRES_DB=employment
DATABASE_URL=postgresql://postgres:password@postgres:5432/employment

# Redis配置
REDIS_URL=redis://redis:6379

# API密钥
OPENAI_API_KEY=your_openai_api_key
ELEVENLABS_API_KEY=your_elevenlabs_api_key

# 爬虫配置
CRAWLER_USER_AGENT=Mozilla/5.0 (compatible; MajorApp/1.0)
CRAWLER_DELAY=2
CRAWLER_MAX_CONCURRENT=5
```

### 13.3 服务启动顺序

```
1. 网络层 → 创建网络
2. 存储层 → PostgreSQL, Redis, Elasticsearch, MinIO
3. 消息队列层 → Zookeeper, Kafka
4. 基础设施层 → Nginx, 监控服务
5. 核心服务层 → api-gateway, user-service
6. 业务服务层 → voice-service, chat-service, crawler-service
7. 前端层 → web-frontend
```

---

## 十四、项目文档结构

```
项目根目录/
├── agents/                          # Agent描述文件
├── .opencode/skill/                 # Skill描述文件
├── frontend/                        # 前端项目
│   ├── web/
│   ├── mobile/
│   └── miniprogram/
├── backend/                         # 后端项目
│   ├── crawler-service/
│   └── ...
├── doc/                             # 文档目录
│   └── crawler_data_analysis.md     # 爬虫数据分析文档
├── docker/                          # Docker配置
├── scripts/                         # 脚本工具
├── 需求设计.md                       # 本文档
└── README.md
```

---

## 十五、附录

### 15.1 参考资料

- [OpenAI API文档](https://platform.openai.com/docs)
- [Whisper文档](https://github.com/openai/whisper)
- [FastAPI文档](https://fastapi.tiangolo.com)
- [LangChain文档](https://python.langchain.com)
- [Scrapy文档](https://docs.scrapy.org)
- [Docker官方文档](https://docs.docker.com)

### 15.2 术语表

| 术语 | 定义 |
|-----|------|
| ASR | Automatic Speech Recognition，语音识别 |
| TTS | Text-to-Speech，语音合成 |
| LLM | Large Language Model，大语言模型 |
| RBAC | Role-Based Access Control，基于角色的访问控制 |
| JWT | JSON Web Token，JSON Web令牌 |
| CDN | Content Delivery Network，内容分发网络 |

---

**文档版本**：2.0  
**创建日期**：2026-01-22  
**最后更新**：2026-01-23  
**主要变更**：文档优化，移除冗余，补充缺失内容，统一格式
