"""
ä¸“ä¸šæ¨èAPIæœåŠ¡
ä¸¥æ ¼æŒ‰ç…§éœ€æ±‚è®¾è®¡æ–‡æ¡£è§„èŒƒå®ç°ï¼š
1. æ•°æ®çœŸå®æ€§åŸåˆ™ï¼šç¦æ­¢ä½¿ç”¨å‡æ•°æ®ï¼Œæ‰€æœ‰æ•°æ®æ¥è‡ªPostgreSQL
2. å¼€å‘æœŸé—´ç¦ç”¨Redisç¼“å­˜ï¼šç›´æ¥æŸ¥è¯¢æ•°æ®åº“ï¼Œæ·»åŠ å“åº”å¤´X-Cache: DISABLED
3. ä¸“ä¸šåˆ—è¡¨æ’åºè§„åˆ™ï¼šé»˜è®¤æŒ‰çƒ­åº¦æŒ‡æ•°ï¼ˆheat_indexï¼‰æ’åº
4. æ”¯æŒåˆ†é¡µã€ç­›é€‰ã€æ’åºå‚æ•°
"""

from fastapi import FastAPI, HTTPException, Query, Response
from fastapi.middleware.cors import CORSMiddleware
from typing import Optional, List, Dict, Any
import psycopg2
from psycopg2.extras import RealDictCursor
import json
import logging
from datetime import datetime
from pydantic import BaseModel, Field
import os

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(
    title="ä¸“ä¸šæ¨èAPI",
    description="ä¸“ä¸šé€‰æ‹©æŒ‡å¯¼åº”ç”¨ - ä¸“ä¸šæ¨èæ ¸å¿ƒæ¥å£",
    version="1.0.0"
)

# CORSé…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# æ•°æ®åº“é…ç½®ï¼ˆä»ç¯å¢ƒå˜é‡æˆ–é»˜è®¤å€¼ï¼‰
DB_CONFIG = {
    'host': os.getenv('DB_HOST', 'localhost'),
    'port': int(os.getenv('DB_PORT', 5432)),
    'database': os.getenv('DB_NAME', 'employment'),
    'user': os.getenv('DB_USER', 'postgres'),
    'password': os.getenv('DB_PASSWORD', 'postgres')
}

def get_db_connection():
    """è·å–æ•°æ®åº“è¿æ¥"""
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        return conn
    except Exception as e:
        logger.error(f"æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail="æ•°æ®åº“è¿æ¥å¤±è´¥")

# =====================================================
# å“åº”æ¨¡å‹å®šä¹‰
# =====================================================

class MajorMarketDataItem(BaseModel):
    """ä¸“ä¸šè¡Œæƒ…æ•°æ®é¡¹"""
    id: int
    major_name: Optional[str]
    category: Optional[str]
    employment_rate: Optional[float]
    avg_salary: Optional[str]
    heat_index: Optional[float]
    crawled_at: Optional[datetime]

class PaginationInfo(BaseModel):
    """åˆ†é¡µä¿¡æ¯"""
    page: int
    page_size: int
    total: int
    total_pages: int

class MajorMarketDataResponse(BaseModel):
    """ä¸“ä¸šè¡Œæƒ…æ•°æ®å“åº”"""
    data: List[MajorMarketDataItem]
    pagination: PaginationInfo

class CategoryItem(BaseModel):
    """å­¦ç§‘åˆ†ç±»é¡¹"""
    category: str
    count: int
    display_name: str

class CategoriesResponse(BaseModel):
    """å­¦ç§‘åˆ†ç±»å“åº”"""
    data: List[CategoryItem]

# =====================================================
# æ•°æ®åº“æŸ¥è¯¢å‡½æ•°
# =====================================================

def get_major_market_data_from_db(
    category: Optional[str] = None,
    page: int = 1,
    page_size: int = 20,
    sort_by: str = "heat_index",
    order: str = "desc"
) -> MajorMarketDataResponse:
    """
    ä»æ•°æ®åº“è·å–ä¸“ä¸šè¡Œæƒ…æ•°æ®
    ä¸¥æ ¼æŒ‰ç…§çƒ­åº¦æŒ‡æ•°æ’åºè§„åˆ™
    """
    try:
        conn = get_db_connection()
        cursor = conn.cursor(cursor_factory=RealDictCursor)
        
        # éªŒè¯æ’åºå­—æ®µ
        valid_sort_fields = ["heat_index", "employment_rate", "crawled_at", "avg_salary"]
        if sort_by not in valid_sort_fields:
            sort_by = "heat_index"  # é»˜è®¤æŒ‰çƒ­åº¦æŒ‡æ•°æ’åº
        
        # éªŒè¯æ’åºæ–¹å‘
        order = "desc" if order.lower() not in ["asc", "desc"] else order.lower()
        
        # æ„å»ºWHEREæ¡ä»¶
        where_conditions = []
        params = []
        
        if category:
            where_conditions.append("category = %s")
            params.append(category)
        
        where_clause = " AND ".join(where_conditions) if where_conditions else "1=1"
        
        # è·å–æ€»æ•°
        count_query = f"""
        SELECT COUNT(*) as total
        FROM major_market_data
        WHERE {where_clause}
        """
        cursor.execute(count_query, params)
        total = cursor.fetchone()['total']
        
        # æ„å»ºæ’åºå­å¥ï¼ˆç‰¹æ®Šå¤„ç†avg_salaryï¼Œå› ä¸ºå®ƒå¯èƒ½æ˜¯å­—ç¬¦ä¸²æ ¼å¼ï¼‰
        if sort_by == "avg_salary":
            # å°è¯•ä»avg_salaryå­—ç¬¦ä¸²ä¸­æå–æ•°å­—è¿›è¡Œæ’åº
            order_clause = f"""
            ORDER BY 
                CASE 
                    WHEN avg_salary ~ '^[0-9]+' THEN 
                        CAST(REGEXP_REPLACE(avg_salary, '[^0-9]', '', 'g') AS INTEGER)
                    ELSE 0 
                END {order},
                avg_salary {order}
            """
        else:
            order_clause = f"ORDER BY {sort_by} {order}, crawled_at DESC"
        
        # è·å–åˆ†é¡µæ•°æ®
        offset = (page - 1) * page_size
        data_query = f"""
        SELECT 
            id, 
            major_name, 
            category, 
            employment_rate, 
            avg_salary, 
            heat_index,
            crawled_at
        FROM major_market_data
        WHERE {where_clause}
        {order_clause}
        LIMIT %s OFFSET %s
        """
        
        cursor.execute(data_query, params + [page_size, offset])
        records = cursor.fetchall()
        
        cursor.close()
        conn.close()
        
        # è½¬æ¢æ•°æ®æ ¼å¼
        data = []
        for record in records:
            # å¤„ç†datetimeå¯¹è±¡
            if record['crawled_at']:
                record['crawled_at'] = record['crawled_at'].isoformat()
            data.append(MajorMarketDataItem(**record))
        
        # æ„å»ºåˆ†é¡µä¿¡æ¯
        total_pages = (total + page_size - 1) // page_size
        pagination = PaginationInfo(
            page=page,
            page_size=page_size,
            total=total,
            total_pages=total_pages
        )
        
        return MajorMarketDataResponse(data=data, pagination=pagination)
        
    except Exception as e:
        logger.error(f"æŸ¥è¯¢ä¸“ä¸šè¡Œæƒ…æ•°æ®å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail="æŸ¥è¯¢ä¸“ä¸šè¡Œæƒ…æ•°æ®å¤±è´¥")

def get_categories_from_db() -> CategoriesResponse:
    """
    ä»æ•°æ®åº“è·å–å­¦ç§‘åˆ†ç±»
    ç»Ÿè®¡æ¯ä¸ªå­¦ç§‘é—¨ç±»çš„ä¸“ä¸šæ•°é‡
    """
    try:
        conn = get_db_connection()
        cursor = conn.cursor(cursor_factory=RealDictCursor)
        
        query = """
        SELECT 
            category,
            COUNT(*) as count,
            CASE 
                WHEN category = 'å·¥å­¦' THEN 'ğŸ”§ å·¥å­¦'
                WHEN category = 'ç†å­¦' THEN 'ğŸ”¬ ç†å­¦'
                WHEN category = 'ç»æµå­¦' THEN 'ğŸ’° ç»æµå­¦'
                WHEN category = 'ç®¡ç†å­¦' THEN 'ğŸ“Š ç®¡ç†å­¦'
                WHEN category = 'åŒ»å­¦' THEN 'âš•ï¸ åŒ»å­¦'
                WHEN category = 'æ³•å­¦' THEN 'âš–ï¸ æ³•å­¦'
                WHEN category = 'æ–‡å­¦' THEN 'ğŸ“š æ–‡å­¦'
                WHEN category = 'å†å²å­¦' THEN 'ğŸ“œ å†å²å­¦'
                WHEN category = 'å“²å­¦' THEN 'ğŸ¤” å“²å­¦'
                WHEN category = 'æ•™è‚²å­¦' THEN 'ğŸ“ æ•™è‚²å­¦'
                WHEN category = 'å†œå­¦' THEN 'ğŸŒ¾ å†œå­¦'
                WHEN category = 'è‰ºæœ¯å­¦' THEN 'ğŸ¨ è‰ºæœ¯å­¦'
                ELSE COALESCE(category, 'å…¶ä»–')
            END as display_name
        FROM major_market_data
        WHERE category IS NOT NULL AND category != ''
        GROUP BY category
        ORDER BY count DESC, category
        """
        
        cursor.execute(query)
        records = cursor.fetchall()
        
        cursor.close()
        conn.close()
        
        # è½¬æ¢æ•°æ®æ ¼å¼
        data = []
        for record in records:
            data.append(CategoryItem(
                category=record['category'],
                count=record['count'],
                display_name=record['display_name']
            ))
        
        return CategoriesResponse(data=data)
        
    except Exception as e:
        logger.error(f"æŸ¥è¯¢å­¦ç§‘åˆ†ç±»å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail="æŸ¥è¯¢å­¦ç§‘åˆ†ç±»å¤±è´¥")

# =====================================================
# APIè·¯ç”±å®šä¹‰
# =====================================================

@app.get("/")
async def root():
    """æ ¹è·¯å¾„ï¼Œæ£€æŸ¥APIçŠ¶æ€"""
    return {
        "message": "ä¸“ä¸šæ¨èAPIæœåŠ¡è¿è¡Œä¸­",
        "version": "1.0.0",
        "timestamp": datetime.now().isoformat(),
        "cache_status": "å¼€å‘æœŸé—´å·²ç¦ç”¨Redisç¼“å­˜"
    }

@app.get("/api/v1/major/market-data", response_model=MajorMarketDataResponse)
async def get_major_market_data(
    page: int = Query(1, ge=1, description="é¡µç "),
    page_size: int = Query(20, ge=1, le=100, description="æ¯é¡µæ•°é‡"),
    category: Optional[str] = Query(None, description="å­¦ç§‘é—¨ç±»ç­›é€‰"),
    sort_by: str = Query("heat_index", description="æ’åºå­—æ®µï¼šheat_index, employment_rate, avg_salary, crawled_at"),
    order: str = Query("desc", description="æ’åºæ–¹å‘ï¼šasc, desc")
):
    """
    è·å–ä¸“ä¸šè¡Œæƒ…æ•°æ®
    
    æ ¸å¿ƒè§„åˆ™ï¼š
    1. æ•°æ®çœŸå®æ€§ï¼šæ‰€æœ‰æ•°æ®æ¥è‡ªPostgreSQLæ•°æ®åº“
    2. ç¼“å­˜ç­–ç•¥ï¼šå¼€å‘æœŸé—´ç¦ç”¨Redisç¼“å­˜ï¼Œç›´æ¥æŸ¥è¯¢æ•°æ®åº“
    3. é»˜è®¤æ’åºï¼šæŒ‰çƒ­åº¦æŒ‡æ•°ï¼ˆheat_indexï¼‰é™åºæ’åº
    4. æ”¯æŒç­›é€‰ï¼šæŒ‰å­¦ç§‘é—¨ç±»ç­›é€‰
    5. æ”¯æŒåˆ†é¡µï¼šæœ€å¤§æ¯é¡µ100æ¡è®°å½•
    """
    try:
        # ä»æ•°æ®åº“è·å–æ•°æ®
        result = get_major_market_data_from_db(
            category=category,
            page=page,
            page_size=page_size,
            sort_by=sort_by,
            order=order
        )
        
        # è¿”å›å“åº”ï¼Œæ·»åŠ ç¦ç”¨ç¼“å­˜çš„æ ‡è¯†
        return Response(
            content=result.json(),
            headers={"X-Cache": "DISABLED"},
            media_type="application/json"
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–ä¸“ä¸šè¡Œæƒ…æ•°æ®å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail="è·å–ä¸“ä¸šè¡Œæƒ…æ•°æ®å¤±è´¥")

@app.get("/api/v1/data/categories", response_model=CategoriesResponse)
async def get_categories():
    """
    è·å–å­¦ç§‘åˆ†ç±»åˆ—è¡¨
    
    æ ¸å¿ƒè§„åˆ™ï¼š
    1. æ•°æ®çœŸå®æ€§ï¼šä»major_market_dataè¡¨ç»Ÿè®¡çœŸå®æ•°æ®
    2. ç¼“å­˜ç­–ç•¥ï¼šå¼€å‘æœŸé—´ç¦ç”¨Redisç¼“å­˜
    3. æ˜¾ç¤ºåç§°ï¼šä¸ºæ¯ä¸ªå­¦ç§‘æ·»åŠ emojiæ ‡è¯†ï¼Œæå‡ç”¨æˆ·ä½“éªŒ
    4. æ’åºè§„åˆ™ï¼šæŒ‰ä¸“ä¸šæ•°é‡é™åºï¼Œæ•°é‡ç›¸åŒæ—¶æŒ‰åç§°æ’åº
    """
    try:
        # ä»æ•°æ®åº“è·å–æ•°æ®
        result = get_categories_from_db()
        
        # è¿”å›å“åº”ï¼Œæ·»åŠ ç¦ç”¨ç¼“å­˜çš„æ ‡è¯†
        return Response(
            content=result.json(),
            headers={"X-Cache": "DISABLED"},
            media_type="application/json"
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–å­¦ç§‘åˆ†ç±»å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail="è·å–å­¦ç§‘åˆ†ç±»å¤±è´¥")

@app.get("/api/v1/major/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # æ£€æŸ¥æ•°æ®åº“è¿æ¥
        cursor.execute("SELECT 1")
        cursor.close()
        conn.close()
        
        return {
            "status": "healthy",
            "database": "connected",
            "cache": "disabled (development mode)",
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
        return {
            "status": "unhealthy",
            "database": "disconnected",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }

# =====================================================
# æ•°æ®åº“ç´¢å¼•ä¼˜åŒ–å»ºè®®ï¼ˆæ–‡æ¡£ç”¨é€”ï¼‰
# =====================================================

OPTIMIZATION_SQLS = """
-- ä¸“ä¸šè¡Œæƒ…æ•°æ®è¡¨ç´¢å¼•ä¼˜åŒ–
-- æ ¹æ®æŸ¥è¯¢éœ€æ±‚åˆ›å»ºå¤åˆç´¢å¼•ï¼Œæå‡æ€§èƒ½

-- 1. çƒ­åº¦æŒ‡æ•°æ’åºç´¢å¼•ï¼ˆé»˜è®¤æ’åºï¼‰
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_major_market_heat_index 
ON major_market_data(heat_index DESC, crawled_at DESC);

-- 2. å­¦ç§‘åˆ†ç±»ç­›é€‰ç´¢å¼•
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_major_market_category 
ON major_market_data(category, heat_index DESC);

-- 3. å°±ä¸šç‡æ’åºç´¢å¼•
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_major_market_employment_rate 
ON major_market_data(employment_rate DESC, crawled_at DESC);

-- 4. çˆ¬å–æ—¶é—´æ’åºç´¢å¼•
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_major_market_crawled_at 
ON major_market_data(crawled_at DESC);

-- 5. å¤åˆç´¢å¼•ï¼šå­¦ç§‘åˆ†ç±» + çƒ­åº¦æŒ‡æ•°ï¼ˆæœ€å¸¸ç”¨æŸ¥è¯¢ç»„åˆï¼‰
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_major_market_category_heat 
ON major_market_data(category, heat_index DESC, crawled_at DESC);

-- 6. å¤åˆç´¢å¼•ï¼šå­¦ç§‘åˆ†ç±» + å°±ä¸šç‡
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_major_market_category_employment 
ON major_market_data(category, employment_rate DESC, crawled_at DESC);

-- 7. è–ªèµ„æ’åºç´¢å¼•ï¼ˆå¤„ç†å­—ç¬¦ä¸²æ ¼å¼çš„è–ªèµ„ï¼‰
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_major_market_salary 
ON major_market_data(
    CASE 
        WHEN avg_salary ~ '^[0-9]+' THEN 
            CAST(REGEXP_REPLACE(avg_salary, '[^0-9]', '', 'g') AS INTEGER)
        ELSE 0 
    END DESC,
    avg_salary DESC
);

-- 8. ä¸»è¦æŸ¥è¯¢å­—æ®µçš„è¦†ç›–ç´¢å¼•
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_major_market_covering 
ON major_market_data(category, heat_index DESC) 
INCLUDE (major_name, employment_rate, avg_salary, crawled_at);

-- ç»Ÿè®¡ä¿¡æ¯æ›´æ–°
ANALYZE major_market_data;
"""

@app.get("/api/v1/admin/optimization-sql")
async def get_optimization_sql():
    """è·å–æ•°æ®åº“ä¼˜åŒ–SQLï¼ˆç®¡ç†å‘˜æ¥å£ï¼‰"""
    return {
        "title": "ä¸“ä¸šè¡Œæƒ…æ•°æ®è¡¨ç´¢å¼•ä¼˜åŒ–SQL",
        "description": "æ ¹æ®APIæŸ¥è¯¢éœ€æ±‚åˆ›å»ºçš„ç´¢å¼•ä¼˜åŒ–è„šæœ¬",
        "sql": OPTIMIZATION_SQLS.strip(),
        "usage": "åœ¨PostgreSQLæ•°æ®åº“ä¸­æ‰§è¡Œä¸Šè¿°SQLè¯­å¥ä»¥ä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½"
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8005)