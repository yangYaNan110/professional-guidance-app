# 通用开发项目 Agent & Skill 设计框架

## 概述

本文档定义了一套通用的Agent和Skill设计框架，用于指导AI辅助开发项目的Agent架构设计和Skill规范。当有具体项目时，AI会根据此框架结合项目描述生成最终的项目规划。

---

## Agent架构设计

### Agent类型分类

```
协调调度Agent (Coordinator) - Primary Agent
    ├── 子Agent群 (Subagents)
    ├── 每个子Agent负责特定技术领域
    └── 子Agent之间可以协作
```

### Agent层级结构

| Agent类型 | 模式 | 职责 | 数量 |
|----------|------|------|------|
| Coordinator | Primary | 需求分析、任务拆分、调度协调、结果整合 | 1 |
| Frontend | Subagent | 前端开发 | 1 |
| Backend | Subagent | 后端开发 | 1 |
| Database | Subagent | 数据库设计和开发 | 1 |
| Infrastructure | Subagent | 基础设施配置（Docker、Nginx等） | 1-N |

### 子Agent设计原则

1. **单一职责**：每个Agent只负责一个技术领域
2. **独立性**：Agent可以独立工作，减少依赖
3. **可扩展性**：可以根据项目需要添加新的Agent
4. **标准接口**：Agent之间通过标准格式通信

### 常见子Agent类型

| Agent名称 | 职责 | 适用场景 |
|----------|------|---------|
| Frontend | 前端开发 | Web应用、移动端 |
| Backend | 后端开发 | API服务、业务逻辑 |
| Database | 数据库 | 数据存储、查询 |
| DevOps | 运维部署 | CI/CD、容器化 |
| Testing | 测试 | 单元测试、集成测试 |
| AI/ML | AI/ML模型集成 | 智能功能 |
| Mobile | 移动端开发 | iOS/Android应用 |
| Frontend-Framework | 特定框架 | React/Vue/Angular等 |
| Backend-Framework | 特定框架 | Django/FastAPI/Spring等 |
| Cloud | 云服务 | AWS/Azure/GCP |

---

## Skill设计规范

### Skill必需字段

每个Skill必须包含以下frontmatter字段：

```yaml
---
name: skill-name              # 必需，1-64字符，小写字母数字，连字符分隔
description: 简短描述          # 必需，1-1024字符
license: MIT                   # 可选
compatibility: opencode        # 可选
metadata:                      # 可选
  audience: developers
  workflow: development
---
```

### Skill命名规范

- 只使用小写字母和数字
- 使用单个连字符分隔
- 格式：`<agent-name>-<action>`
- 示例：`frontend-setup`, `backend-api`, `database-schema`

### Skill内容结构

每个Skill必须包含以下章节：

1. **我做什么**：Skill功能说明
2. **使用场景**：何时使用此Skill
3. **输入格式**：JSON格式的输入说明
4. **输出格式**：JSON格式的输出说明
5. **执行流程**：详细步骤说明
6. **注意事项**：重要提醒

### 每个Agent的必需Skill

每个Agent必须包含以下基础Skill：

1. **需求分析Skill**：`<agent>-analyze`
2. **整体规划Skill**：`<agent>-plan`（包括技术选型、架构设计、目录结构）
3. **项目初始化Skill**：`<agent>-setup`（可选，视情况而定）

### Skill执行顺序

```
需求分析 → 整体规划 → 项目初始化 → 功能开发 → 测试优化
```

---

## 模型选择策略

### 模型分类

根据任务复杂度和类型选择合适的模型：

| 任务类型 | 推荐模型 | 特点 |
|---------|---------|------|
| 复杂架构设计 | Claude Sonnet 4 | 强推理和规划能力 |
| 代码生成 | Claude 3.5 Sonnet | 优秀的代码生成能力 |
| NLP处理 | GPT-4 Turbo | 最强的语言理解能力 |
| UI/UX设计 | GPT-4 Vision | 视觉设计能力 |
| 快速开发 | Claude 3 Haiku | 快速响应，适合简单任务 |
| 数据分析 | Claude Sonnet 4 | 逻辑分析能力强 |
| 复杂问题解决 | Claude Opus 4 | 最强推理能力 |

### Agent默认模型

每个Agent应该在定义中指定默认模型：

| Agent类型 | 默认模型 | 原因 |
|----------|---------|------|
| Coordinator | Claude Sonnet 4 | 需要强推理能力 |
| Frontend | Claude 3.5 Sonnet | 优秀的代码生成 |
| Backend | Claude 3.5 Sonnet | 优秀的代码生成 |
| Database | Claude 3.5 Sonnet | SQL开发 |
| DevOps | Claude 3.5 Sonnet | 配置文件生成 |

### Skill级别模型覆盖

可以在Skill级别覆盖Agent的默认模型：

```markdown
## 推荐模型
- 架构设计：`anthropic/claude-sonnet-4-20250514`
- 代码生成：`anthropic/claude-3-5-sonnet-20241022`
```

---

## Agent调度流程

### 通用开发流程

```
1. 项目启动
   ↓
2. Coordinator分析项目需求 (coordinator-analyze)
   ↓
3. Coordinator制定整体开发计划 (coordinator-plan)
   ↓
4. 并行调度各子Agent进行需求分析和规划
   ├─→ Agent1: agent1-analyze → agent1-plan
   ├─→ Agent2: agent2-analyze → agent2-plan
   └─→ Agent3: agent3-analyze → agent3-plan
   ↓
5. Coordinator整合各Agent的规划结果 (coordinator-integrate)
   ↓
6. 按依赖关系依次调度Agent执行开发任务
   ↓
7. Coordinator进行代码审查 (coordinator-review)
   ↓
8. Coordinator整合所有结果 (coordinator-integrate)
   ↓
9. 生成最终部署配置
   ↓
10. 完成开发
```

### 任务依赖关系管理

```
基础设施层（无依赖）
  ↓
数据库层（依赖基础设施）
  ↓
后端层（依赖数据库）
  ↓
前端层（依赖后端）
  ↓
部署层（依赖前端+后端）
  ↓
测试层（依赖所有层）
```

### 协作模式

#### 1. 顺序协作
Agent A完成 → 输出传递给Agent B → Agent B继续执行

#### 2. 并行协作
多个Agent同时工作，互不干扰

#### 3. 反馈协作
Agent A的输出 → Agent B处理 → 反馈给Agent A修正

#### 4. 集成协作
多个Agent的输出 → Coordinator整合

---

## 输出规范

### Skill输出格式

```json
{
  "skill_name": "skill-name",
  "status": "success/failed/pending",
  "timestamp": "ISO8601",
  "input": {},
  "output": {},
  "metadata": {
    "model_used": "model-id",
    "execution_time_ms": number,
    "tokens_used": {
      "prompt": number,
      "completion": number,
      "total": number
    }
  },
  "next_steps": []
}
```

### Agent输出格式

```json
{
  "agent_name": "agent-name",
  "status": "success/failed/pending",
  "skills_executed": [
    {
      "skill_name": "skill-name",
      "status": "success/failed"
    }
  ],
  "artifacts": {
    "files_created": [],
    "files_modified": [],
    "commands_executed": []
  },
  "summary": "简要总结",
  "next_agent": "下一个Agent名称（可选）"
}
```

---

## 错误处理机制

### Skill执行失败处理

1. 自动重试（最多3次）
2. 记录错误日志
3. 通知Coordinator
4. 跳过非关键任务

### Agent协作失败处理

1. 暂停依赖Agent的执行
2. Coordinator重新评估计划
3. 调整任务顺序或跳过非关键任务

### 冲突解决策略

1. 优先级高的Agent优先
2. Coordinator仲裁冲突
3. 提供冲突解决方案选项

---

## 代码质量标准

### 通用代码规范

- 遵循语言对应的代码风格指南（PEP8、ESLint等）
- 使用类型检查（TypeScript、mypy等）
- 编写单元测试，覆盖率 > 80%
- 代码注释适当，关键逻辑有说明

### 文档规范

- README.md 完整
- API文档（OpenAPI/Swagger）
- 代码注释规范
- 架构图和流程图

### 性能要求

- API响应时间 < 500ms（视项目而定）
- 页面加载时间 < 2s
- 数据库查询优化

---

## 项目规划生成流程

当有具体项目时，AI应按以下流程生成项目规划：

### 输入

1. 项目描述（用户提供的业务需求）
2. 本设计框架（本文档）

### 架构决策

AI在生成项目规划时，需要根据用户需求自主分析并做出以下架构决策：

#### 是否采用微服务架构

AI应根据以下因素分析项目是否需要微服务架构：

**判断标准**：
- **业务复杂度**：业务功能是否复杂，是否可以清晰拆分为多个独立业务域
- **团队规模**：开发团队人数是否超过5人，是否需要并行开发不同模块
- **扩展性需求**：是否需要对不同服务独立扩展（如某个服务需要更多资源）
- **技术多样性**：不同业务模块是否需要不同的技术栈
- **部署频率**：不同服务的部署频率是否差异较大
- **性能要求**：是否需要通过拆分服务来优化性能

**微服务架构适用场景**：
- ✓ 业务边界清晰，模块间耦合度低
- ✓ 需要独立部署和扩展不同服务
- ✓ 不同服务需要不同的技术栈
- ✓ 团队规模较大（5人以上），需要并行开发
- ✓ 对高可用和容错性要求高
- ✓ 需要支持灰度发布和A/B测试

**单体架构适用场景**：
- ✓ 项目规模较小，功能相对简单
- ✓ 团队规模小（3-5人）
- ✓ 开发初期，业务模式尚未稳定
- ✓ 对性能和扩展性要求不高
- ✓ 希望快速迭代和部署

**决策流程**：
```
分析用户需求
    ↓
评估业务复杂度（高/中/低）
    ↓
评估团队规模（大/中/小）
    ↓
评估扩展性需求（高/中/低）
    ↓
判断：如果以上3项中有2项及以上为"高" → 采用微服务架构
    否则 → 采用单体架构
    ↓
在ARCHITECTURE.md中说明架构选择理由
```

**注意事项**：
- 初期可以从单体架构开始，后续根据需要演进为微服务
- 微服务架构会增加运维复杂度，需谨慎选择
- 如果选择微服务，必须在Docker Compose中集成Kafka
- 文档中需要明确说明选择该架构的理由

### 输出

生成完整的项目规划文档，包含：

1. **项目概述**
    - 项目简介
    - 项目目标
    - 核心功能模块

2. **架构决策说明**
    - 选择单体/微服务架构的理由
    - 架构演进路径（如适用）

3. **Agent架构设计**
    - Coordinator配置
    - 子Agent列表和职责
    - Agent协作关系

4. **Skill设计**
    - 每个Agent的Skill列表
    - 每个Skill的详细设计

5. **技术架构**
    - 技术栈选型
    - 架构图
    - 目录结构

6. **开发流程**
    - Agent调度流程
    - 任务依赖关系
    - 开发阶段规划

7. **质量保证**
    - 代码规范
    - 测试策略
    - 部署策略

8. **Docker集成方案**
    - 容器化策略
    - 外部服务集成（优先通过Docker拉取）
    - Docker Compose配置（如为微服务，需包含Kafka）
    - 一键启动/停止流程

---

## Docker集成与部署策略

### 容器化设计原则

1. **优先使用Docker**：所有服务优先使用Docker容器化部署
2. **外部服务Docker化**：额外服务优先通过Docker拉取官方镜像启动
3. **一键启动**：使用Docker Compose实现一键启动、停止
4. **数据持久化**：使用Docker Volume保证数据不丢失
5. **环境隔离**：使用Docker Network实现服务隔离

### 常用外部服务Docker镜像

| 服务名称 | Docker镜像 | 端口 | 说明 |
|---------|-----------|------|------|
| PostgreSQL | postgres:14-alpine | 5432 | 关系型数据库 |
| MySQL | mysql:8.0 | 3306 | 关系型数据库 |
| Redis | redis:7-alpine | 6379 | 缓存和消息队列 |
| MongoDB | mongo:6.0 | 27017 | NoSQL数据库 |
| Nginx | nginx:alpine | 80/443 | 反向代理 |
| RabbitMQ | rabbitmq:3-management | 5672/15672 | 消息队列 |
| Elasticsearch | elasticsearch:8.0 | 9200 | 搜索引擎 |
| MinIO | minio/minio | 9000 | 对象存储 |

### Docker Compose 标准配置

```yaml
version: '3.8'

services:
  # 前端服务
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    environment:
      - API_BASE_URL=http://backend:8000
    depends_on:
      - backend
    networks:
      - app-network

  # 后端服务
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://user:pass@db:5432/dbname
      - REDIS_URL=redis://redis:6379
    depends_on:
      - db
      - redis
    volumes:
      - ./backend:/app
    networks:
      - app-network

  # 数据库服务
  db:
    image: postgres:14-alpine
    environment:
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=pass
      - POSTGRES_DB=dbname
    volumes:
      - postgres-data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    networks:
      - app-network

  # 缓存服务
  redis:
    image: redis:7-alpine
    volumes:
      - redis-data:/data
    ports:
      - "6379:6379"
    networks:
      - app-network

  # 反向代理
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/ssl:/etc/nginx/ssl
    depends_on:
      - frontend
      - backend
    networks:
      - app-network

networks:
  app-network:
    driver: bridge

volumes:
  postgres-data:
  redis-data:
```

### 项目启动流程

#### 一键启动

```bash
# 构建并启动所有服务
docker-compose up -d --build

# 查看服务状态
docker-compose ps

# 查看日志
docker-compose logs -f
```

#### 服务启动顺序

```
1. 启动网络和存储层
   ├── 创建Docker网络
   └── 创建数据卷

2. 启动基础服务
   ├── PostgreSQL数据库
   └── Redis缓存

3. 启动后端服务
   ├── 等待数据库就绪
   ├── 运行数据库迁移
   └── 启动FastAPI应用

4. 启动前端服务
   └── 启动React应用

5. 启动反向代理
   └── 启动Nginx
```

#### 一键停止

```bash
# 停止所有服务
docker-compose down

# 停止并删除数据（谨慎使用）
docker-compose down -v
```

#### 重启服务

```bash
# 重启所有服务
docker-compose restart

# 重启特定服务
docker-compose restart backend
```

### Dockerfile 标准模板

#### 后端Dockerfile

```dockerfile
FROM python:3.10-slim

WORKDIR /app

# 安装依赖
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# 复制代码
COPY . .

# 暴露端口
EXPOSE 8000

# 启动命令
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

#### 前端Dockerfile

```dockerfile
FROM node:18-alpine as builder

WORKDIR /app

# 安装依赖
COPY package*.json ./
RUN npm install

# 构建应用
COPY . .
RUN npm run build

# 生产环境
FROM nginx:alpine

COPY --from=builder /app/dist /usr/share/nginx/html
COPY nginx.conf /etc/nginx/conf.d/default.conf

EXPOSE 80

CMD ["nginx", "-g", "daemon off;"]
```

### 环境变量管理

```yaml
# docker-compose.yml
services:
  backend:
    env_file:
      - .env.backend
  frontend:
    env_file:
      - .env.frontend
```

```bash
# .env.backend
DATABASE_URL=postgresql://user:pass@db:5432/dbname
REDIS_URL=redis://redis:6379
SECRET_KEY=your-secret-key
API_KEY=your-api-key
```

### 开发与生产环境

#### 开发环境

```bash
# 使用docker-compose.dev.yml
docker-compose -f docker-compose.dev.yml up

# 挂载本地代码，热重载
volumes:
  - ./backend:/app
  - ./frontend/src:/app/src
```

#### 生产环境

```bash
# 使用docker-compose.prod.yml
docker-compose -f docker-compose.prod.yml up

# 不挂载代码，使用构建后的镜像
volumes: []
```

### 健康检查

```yaml
services:
  backend:
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  db:
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U user"]
      interval: 10s
      timeout: 5s
      retries: 5
```

### 日志管理

```yaml
services:
  backend:
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
```

### 备份与恢复

```bash
# 备份数据库
docker-compose exec db pg_dump -U user dbname > backup.sql

# 恢复数据库
cat backup.sql | docker-compose exec -T db psql -U user dbname
```

---

## 实际项目设计文档生成规范

当根据用户需求生成实际项目设计文档时，必须包含以下章节：

### 1. 设计思路

详细说明项目的设计思路，包括：

- **业务理解**：对用户需求的理解和解析
- **技术选型理由**：为什么选择特定的技术栈
- **架构设计理由**：为什么选择这种架构模式
- **功能模块划分**：如何将需求拆分为功能模块
- **数据流设计**：数据如何在系统中流动

### 2. 整体规划

项目整体规划包括：

- **开发阶段规划**：明确的开发阶段和里程碑
- **Agent分工**：每个Agent负责什么工作
- **Skill调度**：Skill的执行顺序和依赖关系
- **里程碑交付物**：每个阶段需要交付的内容

### 3. Docker集成方案

- **容器化策略**：哪些服务容器化，如何容器化
- **外部服务集成**：使用哪些外部Docker镜像
- **数据持久化方案**：如何保证数据不丢失
- **网络配置**：服务之间的网络隔离和通信

### 4. 项目启动流程

- **启动步骤**：详细的服务启动顺序
- **依赖关系**：服务之间的依赖关系
- **健康检查**：如何验证服务是否正常启动
- **故障排查**：常见问题的排查方法

### 5. Docker Compose 命令

提供完整的Docker Compose命令：

```bash
# 一键启动
docker-compose up -d

# 一键停止
docker-compose down

# 查看日志
docker-compose logs -f [service-name]

# 重启服务
docker-compose restart [service-name]
```

### 6. 环境配置

- 环境变量列表和说明
- 配置文件示例
- 敏感信息处理方案

---

## 项目文档生成规范

在实际构建项目时，必须生成以下文档：

### 1. 项目根目录文档

#### ARCHITECTURE.md（必需）

项目根目录必须包含 `ARCHITECTURE.md` 文件，描述整体架构：

```markdown
# 项目架构

## 概述
[项目整体架构概述]

## 技术栈
- 前端：[技术栈]
- 后端：[技术栈]
- 数据库：[数据库]
- 缓存：[缓存]
- 其他：[其他技术]

## 架构图
[架构图或架构描述]

## 目录结构
```
project-root/
├── frontend/
├── backend/
├── database/
├── nginx/
└── docker/
```

## 核心模块
1. [模块1]
2. [模块2]
3. [模块3]

## 数据流
[数据在各模块间的流动]

## API设计
[API设计概述]

## 部署架构
[部署架构说明]
```

### 2. 模块文档规范

每个模块目录下必须生成 `README.md` 文件，包含模块描述、目录结构和核心概念：

#### README.md（必需）

模块文档，包含以下内容：

```markdown
# [模块名称]

## 模块概述
[模块的功能和作用]

## 模块职责
- 职责1
- 职责2
- 职责3

## 模块边界
[模块的输入和输出边界]

## 依赖关系
- 依赖的其他模块
- 被其他模块依赖

## 接口定义
[模块提供的接口]

## 数据模型
[模块使用的数据模型]

---

## 目录结构

```
module/
├── src/
│   ├── components/      # 组件/服务
│   ├── utils/           # 工具函数
│   ├── types/           # 类型定义
│   ├── config/          # 配置文件
│   └── index.ts         # 入口文件
├── tests/               # 测试文件
├── package.json
└── README.md
```

### 目录说明

### src/
- components/：[说明]
- utils/：[说明]
- types/：[说明]
- config/：[说明]

### tests/
[测试文件组织说明]

### 文件命名规范
[模块内文件命名规范]

---

## 核心概念

### 概念1
- **定义**：[概念定义]
- **用途**：[概念用途]
- **实现**：[概念如何实现]
- **示例**：[代码示例]

### 概念2
- **定义**：[概念定义]
- **用途**：[概念用途]
- **实现**：[概念如何实现]
- **示例**：[代码示例]

## 设计模式
[模块中使用的设计模式]

## 关键算法
[模块中的关键算法说明]

## 最佳实践
- 最佳实践1
- 最佳实践2

## 常见问题

### Q1: [问题]
**A**: [答案]

### Q2: [问题]
**A**: [答案]
```

### 3. 文档生成时机

- **ARCHITECTURE.md**：在项目规划阶段生成，由Coordinator负责
- **README.md**：在每个Agent完成规划后生成，包含模块描述、目录结构和核心概念

### 4. 文档更新机制

- 代码变更时同步更新文档
- 定期审查文档准确性
- 文档变更记录在文档头部

### 5. 文档模板

#### 根目录 ARCHITECTURE.md 模板

```markdown
# {PROJECT_NAME} 项目架构

## 概述

{PROJECT_NAME} 是一个 {PROJECT_TYPE} 项目，主要实现 {CORE_FEATURES}。

## 技术栈

| 层级 | 技术 | 版本 | 用途 |
|-----|------|------|------|
| 前端 | {FRAMEWORK} | {VERSION} | 用户界面 |
| 后端 | {FRAMEWORK} | {VERSION} | API服务 |
| 数据库 | {DATABASE} | {VERSION} | 数据存储 |
| 缓存 | {CACHE} | {VERSION} | 缓存 |
| 部署 | {DEPLOY} | {VERSION} | 容器化部署 |

## 架构图

{ARCHITECTURE_DIAGRAM}

## 核心模块

### 1. {MODULE1_NAME}
- **职责**：{RESPONSIBILITY}
- **技术**：{TECH}
- **路径**：{PATH}

### 2. {MODULE2_NAME}
- **职责**：{RESPONSIBILITY}
- **技术**：{TECH}
- **路径**：{PATH}

### 3. {MODULE3_NAME}
- **职责**：{RESPONSIBILITY}
- **技术**：{TECH}
- **路径**：{PATH}

## 数据流

```
{DATA_FLOW_DIAGRAM}
```

## API设计

### 主要接口
- {ENDPOINT1}
- {ENDPOINT2}
- {ENDPOINT3}

### 认证方式
{AUTH_METHOD}

## 部署架构

```
{DEPLOYMENT_ARCHITECTURE}
```

## 环境变量

| 变量名 | 说明 | 默认值 |
|-------|------|-------|
| {VAR1} | {DESCRIPTION} | {DEFAULT} |
| {VAR2} | {DESCRIPTION} | {DEFAULT} |

## 启动流程

1. {STEP1}
2. {STEP2}
3. {STEP3}

## 扩展性设计

{SCALABILITY_CONSIDERATIONS}

## 安全考虑

{SECURITY_CONSIDERATIONS}

---
**最后更新**：{DATE}
**维护者**：{MAINTAINER}
```

#### 模块文档模板

```markdown
# {MODULE_NAME}

## 模块概述

{MODULE_NAME} 负责 {MODULE_PURPOSE}。

## 模块职责

1. {RESPONSIBILITY1}
2. {RESPONSIBILITY2}
3. {RESPONSIBILITY3}

## 模块边界

### 输入
- {INPUT1}
- {INPUT2}

### 输出
- {OUTPUT1}
- {OUTPUT2}

## 依赖关系

### 依赖的其他模块
- {DEPENDENCY1} - {REASON}
- {DEPENDENCY2} - {REASON}

### 被其他模块依赖
- {DEPENDENT1} - {REASON}
- {DEPENDENT2} - {REASON}

## 接口定义

### 公开接口
```typescript
interface {INTERFACE_NAME} {
  // 接口定义
}
```

### 内部接口
```typescript
interface {INTERNAL_INTERFACE} {
  // 接口定义
}
```

## 数据模型

### {MODEL1}
```typescript
interface {MODEL1} {
  // 数据模型定义
}
```

### {MODEL2}
```typescript
interface {MODEL2} {
  // 数据模型定义
}
```

## 配置说明

| 配置项 | 说明 | 默认值 |
|-------|------|-------|
| {CONFIG1} | {DESCRIPTION} | {DEFAULT} |
| {CONFIG2} | {DESCRIPTION} | {DEFAULT} |

## 错误处理

### 错误码
| 错误码 | 说明 | 处理方式 |
|-------|------|---------|
| {ERROR1} | {DESCRIPTION} | {HANDLING} |
| {ERROR2} | {DESCRIPTION} | {HANDLING} |

## 性能指标

- {METRIC1}：{VALUE}
- {METRIC2}：{VALUE}

## 测试策略

- {TEST_STRATEGY1}
- {TEST_STRATEGY2}

---

## 目录结构

```
module/
├── src/
│   ├── components/      # 组件/服务
│   ├── utils/           # 工具函数
│   ├── types/           # 类型定义
│   ├── config/          # 配置文件
│   └── index.ts         # 入口文件
├── tests/               # 测试文件
├── package.json
└── README.md
```

### 目录说明

#### src/
- components/：{DESCRIPTION}
- utils/：{DESCRIPTION}
- types/：{DESCRIPTION}
- config/：{DESCRIPTION}

#### tests/
{TEST_ORGANIZATION}

### 文件命名规范
{NAMING_CONVENTION}

---

## 核心概念

### 概念1
- **定义**：{DEFINITION}
- **用途**：{PURPOSE}
- **实现**：{IMPLEMENTATION}
- **示例**：{EXAMPLE}

### 概念2
- **定义**：{DEFINITION}
- **用途**：{PURPOSE}
- **实现**：{IMPLEMENTATION}
- **示例**：{EXAMPLE}

## 设计模式
{DESIGN_PATTERNS_USED}

## 关键算法
{KEY_ALGORITHMS}

## 最佳实践
- {BEST_PRACTICE1}
- {BEST_PRACTICE2}

## 常见问题

### Q1: {QUESTION}
**A**: {ANSWER}

### Q2: {QUESTION}
**A**: {ANSWER}

---
**最后更新**：{DATE}
**负责人**：{OWNER}
```

---

## 微服务架构设计规范

### 微服务架构适用场景

当服务比较复杂、需要拆分时，可以设计成微服务架构。适用场景包括：

- 服务之间耦合度低，业务边界清晰
- 需要独立部署和扩展不同服务
- 不同服务需要不同的技术栈
- 团队规模较大，需要并行开发
- 对高可用和容错性要求高

### 微服务架构设计原则

1. **单一职责**：每个微服务只负责一个业务功能
2. **独立部署**：每个微服务可以独立部署和升级
3. **数据库分离**：每个微服务拥有独立的数据库
4. **异步通信**：使用消息队列实现服务间异步通信
5. **容错设计**：服务降级、熔断、重试机制
6. **可观测性**：完善的日志、监控、追踪

### 微服务拆分策略

#### 按业务领域拆分（推荐）

```
电商系统示例：
- 用户服务
- 商品服务
- 订单服务
- 支付服务
- 库存服务
- 通知服务
```

#### 按功能模块拆分

```
内容管理系统示例：
- 内容管理服务
- 评论服务
- 搜索服务
- 推荐服务
- 统计服务
```

### Kafka消息队列使用规范

#### Kafka架构

```
┌─────────────────────────────────────────┐
│           API Gateway                   │
└─────────────────────────────────────────┘
                   │
        ┌──────────┼──────────┐
        ↓          ↓          ↓
┌─────────┐  ┌─────────┐  ┌─────────┐
│ Service │  │ Service │  │ Service │
│   A     │  │   B     │  │   C     │
└────┬────┘  └────┬────┘  └────┬────┘
     │            │            │
     └────────────┼────────────┘
                  ↓
         ┌────────────────┐
         │     Kafka      │
         │  (Message     │
         │   Queue)      │
         └────────────────┘
                  │
     ┌────────────┼────────────┐
     ↓            ↓            ↓
┌─────────┐  ┌─────────┐  ┌─────────┐
│ Service │  │ Service │  │ Service │
│   D     │  │   E     │  │   F     │
└─────────┘  └─────────┘  └─────────┘
```

#### Kafka Topic设计

```yaml
# 用户相关事件
user-events:
  partitions: 3
  replication-factor: 2
  topics:
    - user.created
    - user.updated
    - user.deleted

# 订单相关事件
order-events:
  partitions: 5
  replication-factor: 2
  topics:
    - order.created
    - order.paid
    - order.shipped
    - order.completed

# 通知事件
notification-events:
  partitions: 3
  replication-factor: 2
  topics:
    - email.send
    - sms.send
    - push.send
```

#### Docker Compose Kafka配置

```yaml
version: '3.8'

services:
  # Zookeeper（Kafka依赖）
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    volumes:
      - zookeeper-data:/var/lib/zookeeper/data
      - zookeeper-logs:/var/lib/zookeeper/log
    networks:
      - microservices-network

  # Kafka消息队列
  kafka:
    image: confluentinc/cp-kafka:7.4.0
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
    volumes:
      - kafka-data:/var/lib/kafka/data
    networks:
      - microservices-network

  # Kafka UI（可选，用于管理）
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    depends_on:
      - kafka
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
    networks:
      - microservices-network

  # 微服务示例
  user-service:
    build: ./services/user-service
    depends_on:
      - kafka
      - postgres
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
    networks:
      - microservices-network

  order-service:
    build: ./services/order-service
    depends_on:
      - kafka
      - postgres
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
    networks:
      - microservices-network

  notification-service:
    build: ./services/notification-service
    depends_on:
      - kafka
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
    networks:
      - microservices-network

  # API Gateway
  api-gateway:
    image: nginx:alpine
    ports:
      - "80:80"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
    depends_on:
      - user-service
      - order-service
    networks:
      - microservices-network

networks:
  microservices-network:
    driver: bridge

volumes:
  zookeeper-data:
  zookeeper-logs:
  kafka-data:
```

#### 服务通信模式

##### 1. 同步通信（HTTP/REST）

```python
# 服务A调用服务B
async def get_user_info(user_id: str):
    async with httpx.AsyncClient() as client:
        response = await client.get(
            f"http://user-service:8001/users/{user_id}"
        )
        return response.json()
```

##### 2. 异步通信（Kafka）

```python
# 服务A发送事件到Kafka
async def publish_user_created(user_data: dict):
    producer = AIOKafkaProducer(bootstrap_servers="kafka:29092")
    await producer.start()
    try:
        await producer.send_and_wait(
            "user.events",
            json.dumps({"type": "user.created", "data": user_data}).encode()
        )
    finally:
        await producer.stop()

# 服务B监听Kafka事件
async def consume_user_events():
    consumer = AIOKafkaConsumer(
        "user.events",
        bootstrap_servers="kafka:29092"
    )
    await consumer.start()
    try:
        async for msg in consumer:
            event = json.loads(msg.value.decode())
            if event["type"] == "user.created":
                handle_user_created(event["data"])
    finally:
        await consumer.stop()
```

#### 微服务目录结构

```
microservices-project/
├── services/
│   ├── user-service/
│   │   ├── src/
│   │   ├── README.md           # 微服务文档
│   │   ├── Dockerfile
│   │   └── requirements.txt
│   ├── order-service/
│   │   ├── src/
│   │   ├── README.md           # 微服务文档
│   │   ├── Dockerfile
│   │   └── requirements.txt
│   ├── notification-service/
│   │   ├── src/
│   │   ├── README.md           # 微服务文档
│   │   ├── Dockerfile
│   │   └── requirements.txt
│   └── api-gateway/
│       ├── nginx.conf
│       ├── README.md           # API网关文档
│       └── Dockerfile
├── docker/
│   ├── docker-compose.yml      # 开发环境
│   ├── docker-compose.prod.yml  # 生产环境
│   └── .env.example
├── shared/
│   ├── schemas/                # 共享数据模型
│   ├── utils/                  # 共享工具
│   └── config/                 # 共享配置
├── ARCHITECTURE.md
└── README.md
```

#### 微服务README.md模板

```markdown
# {SERVICE_NAME}

## 服务概述

{SERVICE_NAME} 负责 {SERVICE_PURPOSE}。

## 服务职责

1. {RESPONSIBILITY1}
2. {RESPONSIBILITY2}

## API接口

### GET /api/users/{id}
获取用户信息

### POST /api/users
创建用户

### PUT /api/users/{id}
更新用户信息

### DELETE /api/users/{id}
删除用户

## 事件发布

### user.created
当用户创建时发布此事件

```json
{
  "type": "user.created",
  "data": {
    "user_id": "123",
    "email": "user@example.com"
  },
  "timestamp": "2024-01-22T10:00:00Z"
}
```

### user.updated
当用户更新时发布此事件

## 事件订阅

### order.created
监听订单创建事件，发送欢迎邮件

## 数据库

使用 {DATABASE}，主要表：
- users
- user_profiles

## 配置

| 配置项 | 说明 | 默认值 |
|-------|------|-------|
| PORT | 服务端口 | 8001 |
| KAFKA_BOOTSTRAP_SERVERS | Kafka地址 | kafka:29092 |
| DATABASE_URL | 数据库连接 | postgres://... |

## 健康检查

GET /health

```json
{
  "status": "healthy",
  "timestamp": "2024-01-22T10:00:00Z"
}
```

---

## 目录结构

```
service/
├── src/
│   ├── api/                # API路由
│   ├── models/             # 数据模型
│   ├── services/           # 业务逻辑
│   ├── events/             # 事件处理
│   │   ├── publishers.py   # 事件发布
│   │   └── consumers.py    # 事件消费
│   ├── utils/              # 工具函数
│   └── main.py             # 应用入口
├── tests/
├── Dockerfile
└── README.md
```

---

## 核心概念

### 事件驱动架构

服务通过发布和订阅事件进行异步通信，降低耦合度。

### 最终一致性

服务之间不使用分布式事务，通过事件实现最终一致性。

### 幂等性

事件处理需要保证幂等性，避免重复处理。

### 重试机制

消费失败时自动重试，设置合理的重试策略。

## 最佳实践

- 服务状态无状态化
- 事件命名统一规范（resource.action）
- 添加事件追踪ID
- 设置合理的重试策略
- 监控消息积压情况

## 常见问题

### Q1: 如何保证消息顺序？
**A**: 使用分区键，相同key的消息发送到同一分区。

### Q2: 如何处理消息重复？
**A**: 实现幂等性处理，使用事件ID去重。

### Q3: 如何实现服务降级？
**A**: 使用断路器模式，失败时返回降级数据。

---
**最后更新**：{DATE}
**负责人**：{OWNER}
```

#### 微服务部署流程

```bash
# 启动所有微服务
docker-compose -f docker-compose.yml up -d

# 查看服务状态
docker-compose ps

# 查看Kafka消息
docker-compose exec kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic user.events \
  --from-beginning

# 重启特定服务
docker-compose restart user-service

# 查看服务日志
docker-compose logs -f user-service
```

#### 微服务监控

```yaml
# Prometheus监控配置
services:
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    networks:
      - microservices-network

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    networks:
      - microservices-network
```

---

## 模板文件结构

### 目录结构

```
project-root/
├── .opencode/
│   ├── opencode.json           # 项目配置
│   ├── agent/                   # Agent定义目录
│   │   ├── coordinator.md       # Coordinator定义
│   │   ├── frontend.md          # Frontend Agent定义
│   │   ├── backend.md           # Backend Agent定义
│   │   └── ...
│   └── skill/                   # Skill定义目录
│       ├── coordinator/
│       │   ├── analyze/SKILL.md
│       │   ├── plan/SKILL.md
│       │   └── ...
│       ├── frontend/
│       │   ├── analyze/SKILL.md
│       │   ├── plan/SKILL.md
│       │   └── ...
│       └── ...
├── frontend/                    # 前端项目
│   ├── src/
│   ├── README.md               # 模块文档（必需）
│   ├── Dockerfile
│   └── ...
├── backend/                     # 后端项目
│   ├── src/
│   ├── README.md               # 模块文档（必需）
│   ├── Dockerfile
│   └── ...
├── database/                    # 数据库项目
│   ├── migrations/
│   ├── README.md               # 模块文档（必需）
│   └── ...
├── nginx/                       # Nginx配置
│   ├── nginx.conf
│   ├── README.md               # 模块文档（必需）
│   └── ...
├── docker/                      # Docker配置
│   ├── docker-compose.yml       # 开发环境
│   ├── docker-compose.prod.yml   # 生产环境
│   └── .env.example             # 环境变量模板
├── ARCHITECTURE.md             # 项目架构文档（必需）
├── PROJECT_PLAN.md              # 项目规划文档
├── DEV_PROCESS.md               # 开发流程文档
└── README.md                    # 项目说明
```

### 必需文档清单

| 文档位置 | 文件名 | 生成时机 | 负责Agent |
|---------|-------|---------|-----------|
| 项目根目录 | ARCHITECTURE.md | 项目规划阶段 | Coordinator |
| 模块目录 | README.md | 模块规划后 | 对应Agent |

---

## 使用示例

### 示例1：Web应用项目

**Agent配置**：
- Coordinator
- Frontend (React)
- Backend (FastAPI)
- Database (PostgreSQL)
- DevOps (Docker, Nginx)

**Skill配置**：
- 每个Agent包含 analyze + plan + setup + 特定功能Skill

### 示例2：移动应用项目

**Agent配置**：
- Coordinator
- Mobile (React Native / Flutter)
- Backend (Node.js / Go)
- Database (MongoDB)
- DevOps (Docker)

**Skill配置**：
- 移动端特定Skill (UI组件、导航、原生模块)
- 后端特定Skill (API、认证、推送)

### 示例3：AI应用项目

**Agent配置**：
- Coordinator
- Frontend (Vue.js)
- Backend (Python FastAPI)
- AI/ML (模型集成、数据处理)
- Database (PostgreSQL + Redis)
- DevOps (Docker, GPU环境)

**Skill配置**：
- AI/ML特定Skill (模型训练、推理、数据处理)

---

## 扩展指南

### 添加新Agent

1. 创建Agent定义文件 `.opencode/agent/<agent-name>.md`
2. 定义Agent职责和技术栈
3. 创建对应的Skill目录
4. 创建必需的Skill (analyze, plan)
5. 根据需要添加功能Skill

### 添加新Skill

1. 确定Skill归属的Agent
2. 遵循Skill命名规范
3. 编写Skill文档，包含必需字段
4. 在Agent定义中引用Skill

---

## 最佳实践

1. **保持简单**：不要过度设计，从必需的Agent和Skill开始
2. **逐步迭代**：先建立基础架构，再逐步添加功能
3. **文档先行**：先写好Agent和Skill文档，再开始开发
4. **自动化测试**：为每个Skill编写测试
5. **持续集成**：建立CI/CD流程
6. **代码审查**：定期审查生成的代码质量

---

## 附录

### 常用Agent模板

#### Frontend Agent 模板

```markdown
---
description: 前端开发Agent，负责前端架构、组件开发和UI实现
mode: subagent
model: anthropic/claude-3-5-sonnet-20241022
temperature: 0.2
tools:
  write: true
  edit: true
  bash: true
  read: true
  skill: true
instructions:
  - "./PROJECT_PLAN.md"
  - "./DEV_PROCESS.md"
---

你是前端开发Agent。

## 我做什么
- 前端需求分析
- 技术选型和架构设计
- 组件开发
- 状态管理
- API集成

## 可用技能
- frontend-analyze
- frontend-plan
- frontend-setup
- frontend-component
- frontend-state
- frontend-api
```

#### Backend Agent 模板

```markdown
---
description: 后端开发Agent，负责后端架构、API开发和业务逻辑
mode: subagent
model: anthropic/claude-3-5-sonnet-20241022
temperature: 0.2
tools:
  write: true
  edit: true
  bash: true
  read: true
  skill: true
instructions:
  - "./PROJECT_PLAN.md"
  - "./DEV_PROCESS.md"
---

你是后端开发Agent。

## 我做什么
- 后端需求分析
- 技术选型和架构设计
- API开发
- 业务逻辑实现
- 数据库操作

## 可用技能
- backend-analyze
- backend-plan
- backend-setup
- backend-api
- backend-service
```

### 常用Skill模板

#### analyze Skill 模板

```markdown
---
name: <agent>-analyze
description: 分析<agent>需求和功能
license: MIT
compatibility: opencode
---

## 我做什么
分析<agent>的功能需求和技术需求。

## 使用场景
项目启动时或需求变更时使用。

## 输入格式
```json
{
  "project_description": "项目描述",
  "requirements": []
}
```

## 输出格式
```json
{
  "functional_requirements": [],
  "technical_requirements": [],
  "dependencies": [],
  "risks": []
}
```

## 执行流程
1. 分析项目描述
2. 识别功能需求
3. 识别技术需求
4. 分析依赖关系
5. 识别潜在风险
```

#### plan Skill 模板

```markdown
---
name: <agent>-plan
description: <agent>整体规划，包括技术选型、架构设计、目录结构
license: MIT
compatibility: opencode
---

## 我做什么
制定<agent>的整体规划，包括技术选型、架构设计和目录结构。

## 使用场景
需求分析完成后使用。

## 输入格式
```json
{
  "requirements": {},
  "project_context": {}
}
```

## 输出格式
```json
{
  "tech_stack": {},
  "architecture": {},
  "directory_structure": {},
  "dependencies": []
}
```

## 执行流程
1. 分析需求
2. 选择技术栈
3. 设计架构
4. 设计目录结构
5. 确定依赖关系

## 推荐模型
- 架构设计：`anthropic/claude-sonnet-4-20250514`
- 技术选型：`anthropic/claude-3-5-sonnet-20241022`
```

---

## 总结

本设计框架提供了一套通用的Agent和Skill设计规范，适用于大多数开发项目。当有具体项目时，AI应：

1. **理解项目描述**
   - 分析用户提供的业务需求
   - 识别核心功能和技术需求
   - 评估项目复杂度和规模

2. **根据本框架设计合适的Agent架构**
   - 确定所需的Agent类型和数量
   - 定义每个Agent的职责
   - 规划Agent之间的协作关系

3. **为每个Agent设计必要的Skill**
   - 每个Agent包含analyze和plan基础Skill
   - 根据需求添加功能Skill
   - 为每个Skill选择合适的模型

4. **生成完整的项目规划文档**
   - 包含设计思路和整体规划
   - 技术架构和目录结构
   - Docker集成方案
   - 一键启动/停止流程

5. **创建对应的Agent和Skill文件**
   - 在.opencode/agent/下创建Agent定义
   - 在.opencode/skill/下创建Skill定义
   - 遵循命名规范和内容结构

6. **确保Docker化部署**
   - 优先使用Docker容器化所有服务
   - 额外服务通过Docker官方镜像拉取
   - 提供docker-compose一键启动配置
   - 包含启动流程、健康检查和故障排查说明

这样可以确保项目开发的系统性、一致性和可维护性，同时提供便捷的部署方式。
